{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a9bfb86-daee-4d11-9aaf-ef2d88db7225",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb28b0df-bca2-45fc-b929-0baa7202d872",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Create Delta Table**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4cc43ac-a6e7-4540-bcbe-2d80b704f14b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## using sql api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95d706c9-c8f9-4888-9e25-6ec3d6c51d7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-5945745070037240>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_cell_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msql\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcreate table delta.deltaschema.deltatable\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m(\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  id int not null,\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  name string,\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  age int\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124musing delta\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2541\u001B[0m, in \u001B[0;36mInteractiveShell.run_cell_magic\u001B[0;34m(self, magic_name, line, cell)\u001B[0m\n",
       "\u001B[1;32m   2539\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n",
       "\u001B[1;32m   2540\u001B[0m     args \u001B[38;5;241m=\u001B[39m (magic_arg_s, cell)\n",
       "\u001B[0;32m-> 2541\u001B[0m     result \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m   2543\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n",
       "\u001B[1;32m   2544\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n",
       "\u001B[1;32m   2545\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n",
       "\u001B[1;32m   2546\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:147\u001B[0m, in \u001B[0;36mSqlMagic.sql\u001B[0;34m(self, line, cell)\u001B[0m\n",
       "\u001B[1;32m    143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n",
       "\u001B[1;32m    144\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot run \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124mql command because spark connect initialization failed and no stacktrace was available.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    145\u001B[0m     )\n",
       "\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_py4j:\n",
       "\u001B[0;32m--> 147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexecute_via_py4j(cell)\n",
       "\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexecute_via_sql_comm_handler(cell)\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:231\u001B[0m, in \u001B[0;36mSqlMagic.execute_via_py4j\u001B[0;34m(self, cell)\u001B[0m\n",
       "\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdriver_activity_logger\u001B[38;5;241m.\u001B[39mlogExecuteCommandEvent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSQL_MAGIC_PY4J_FAILED\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    230\u001B[0m                                                        json\u001B[38;5;241m.\u001B[39mdumps(get_debug_info(e)))\n",
       "\u001B[0;32m--> 231\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
       "\u001B[1;32m    232\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdriver_activity_logger\u001B[38;5;241m.\u001B[39mlogExecuteCommandEvent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSQL_MAGIC_PY4J_SUCCEEDED\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:227\u001B[0m, in \u001B[0;36mSqlMagic.execute_via_py4j\u001B[0;34m(self, cell)\u001B[0m\n",
       "\u001B[1;32m    225\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecuting subquery: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquery_text\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, file\u001B[38;5;241m=\u001B[39msys\u001B[38;5;241m.\u001B[39m__stdout__)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n",
       "\u001B[1;32m    226\u001B[0m         sql_directive \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentry_point\u001B[38;5;241m.\u001B[39mgetSqlDirective(query_text)\n",
       "\u001B[0;32m--> 227\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_sql_directive(sql_directive, i \u001B[38;5;241m==\u001B[39m number_of_sub_queries \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m)\n",
       "\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdriver_activity_logger\u001B[38;5;241m.\u001B[39mlogExecuteCommandEvent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSQL_MAGIC_PY4J_FAILED\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    230\u001B[0m                                                        json\u001B[38;5;241m.\u001B[39mdumps(get_debug_info(e)))\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:249\u001B[0m, in \u001B[0;36mSqlMagic.handle_sql_directive\u001B[0;34m(self, sql_directive, is_last_query)\u001B[0m\n",
       "\u001B[1;32m    247\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_query_request_result(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSELECT * FROM \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtable_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    248\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m directive_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNoDirective\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
       "\u001B[0;32m--> 249\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_query_request_result(sql_directive\u001B[38;5;241m.\u001B[39msql())\n",
       "\u001B[1;32m    250\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m df \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(df\u001B[38;5;241m.\u001B[39mschema) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[1;32m    251\u001B[0m         \u001B[38;5;66;03m# E.g. \"create or replace temp view abc as select 1\" gets us here and we should not return a result in this case.\u001B[39;00m\n",
       "\u001B[1;32m    252\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:124\u001B[0m, in \u001B[0;36mSqlMagic.get_query_request_result\u001B[0;34m(self, query)\u001B[0m\n",
       "\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(widget_bindings \u001B[38;5;241m:=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdbutils\u001B[38;5;241m.\u001B[39mwidgets\u001B[38;5;241m.\u001B[39mgetAll()) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[1;32m    123\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdriver_activity_logger\u001B[38;5;241m.\u001B[39mlogExecuteCommandEvent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPARAM_SYNTAX_USAGE\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[0;32m--> 124\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39masserting_spark\u001B[38;5;241m.\u001B[39msql(query, widget_bindings)\n",
       "\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/session.py:736\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    733\u001B[0m         _views\u001B[38;5;241m.\u001B[39mappend(SubqueryAlias(df\u001B[38;5;241m.\u001B[39m_plan, name))\n",
       "\u001B[1;32m    735\u001B[0m cmd \u001B[38;5;241m=\u001B[39m SQL(sqlQuery, _args, _named_args, _views)\n",
       "\u001B[0;32m--> 736\u001B[0m data, properties, ei \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mexecute_command(cmd\u001B[38;5;241m.\u001B[39mcommand(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client))\n",
       "\u001B[1;32m    737\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msql_command_result\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m properties:\n",
       "\u001B[1;32m    738\u001B[0m     df \u001B[38;5;241m=\u001B[39m DataFrame(CachedRelation(properties[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msql_command_result\u001B[39m\u001B[38;5;124m\"\u001B[39m]), \u001B[38;5;28mself\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1297\u001B[0m, in \u001B[0;36mSparkConnectClient.execute_command\u001B[0;34m(self, command, observations, extra_request_metadata)\u001B[0m\n",
       "\u001B[1;32m   1295\u001B[0m     req\u001B[38;5;241m.\u001B[39muser_context\u001B[38;5;241m.\u001B[39muser_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_user_id\n",
       "\u001B[1;32m   1296\u001B[0m req\u001B[38;5;241m.\u001B[39mplan\u001B[38;5;241m.\u001B[39mcommand\u001B[38;5;241m.\u001B[39mCopyFrom(command)\n",
       "\u001B[0;32m-> 1297\u001B[0m data, _, metrics, observed_metrics, properties \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_and_fetch(\n",
       "\u001B[1;32m   1298\u001B[0m     req, observations \u001B[38;5;129;01mor\u001B[39;00m {}, extra_request_metadata\n",
       "\u001B[1;32m   1299\u001B[0m )\n",
       "\u001B[1;32m   1300\u001B[0m \u001B[38;5;66;03m# Create a query execution object.\u001B[39;00m\n",
       "\u001B[1;32m   1301\u001B[0m ei \u001B[38;5;241m=\u001B[39m ExecutionInfo(metrics, observed_metrics)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1755\u001B[0m, in \u001B[0;36mSparkConnectClient._execute_and_fetch\u001B[0;34m(self, req, observations, extra_request_metadata, self_destruct)\u001B[0m\n",
       "\u001B[1;32m   1752\u001B[0m properties: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m {}\n",
       "\u001B[1;32m   1754\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Progress(handlers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_progress_handlers, operation_id\u001B[38;5;241m=\u001B[39mreq\u001B[38;5;241m.\u001B[39moperation_id) \u001B[38;5;28;01mas\u001B[39;00m progress:\n",
       "\u001B[0;32m-> 1755\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m response \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_and_fetch_as_iterator(\n",
       "\u001B[1;32m   1756\u001B[0m         req, observations, extra_request_metadata \u001B[38;5;129;01mor\u001B[39;00m [], progress\u001B[38;5;241m=\u001B[39mprogress\n",
       "\u001B[1;32m   1757\u001B[0m     ):\n",
       "\u001B[1;32m   1758\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, StructType):\n",
       "\u001B[1;32m   1759\u001B[0m             schema \u001B[38;5;241m=\u001B[39m response\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1731\u001B[0m, in \u001B[0;36mSparkConnectClient._execute_and_fetch_as_iterator\u001B[0;34m(self, req, observations, extra_request_metadata, progress)\u001B[0m\n",
       "\u001B[1;32m   1729\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m kb\n",
       "\u001B[1;32m   1730\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n",
       "\u001B[0;32m-> 1731\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_error(error)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:2047\u001B[0m, in \u001B[0;36mSparkConnectClient._handle_error\u001B[0;34m(self, error)\u001B[0m\n",
       "\u001B[1;32m   2045\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mthread_local\u001B[38;5;241m.\u001B[39minside_error_handling \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[1;32m   2046\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(error, grpc\u001B[38;5;241m.\u001B[39mRpcError):\n",
       "\u001B[0;32m-> 2047\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_rpc_error(error)\n",
       "\u001B[1;32m   2048\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(error, \u001B[38;5;167;01mValueError\u001B[39;00m):\n",
       "\u001B[1;32m   2049\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot invoke RPC\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(error) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(error):\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:2149\u001B[0m, in \u001B[0;36mSparkConnectClient._handle_rpc_error\u001B[0;34m(self, rpc_error)\u001B[0m\n",
       "\u001B[1;32m   2134\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n",
       "\u001B[1;32m   2135\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPython versions in the Spark Connect client and server are different. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   2136\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo execute user-defined functions, client and server should have the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   2145\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://docs.databricks.com/en/release-notes/serverless.html.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   2146\u001B[0m                 )\n",
       "\u001B[1;32m   2147\u001B[0m             \u001B[38;5;66;03m# END-EDGE\u001B[39;00m\n",
       "\u001B[0;32m-> 2149\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m convert_exception(\n",
       "\u001B[1;32m   2150\u001B[0m                 info,\n",
       "\u001B[1;32m   2151\u001B[0m                 status\u001B[38;5;241m.\u001B[39mmessage,\n",
       "\u001B[1;32m   2152\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fetch_enriched_error(info),\n",
       "\u001B[1;32m   2153\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_display_server_stack_trace(),\n",
       "\u001B[1;32m   2154\u001B[0m             ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m   2156\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m SparkConnectGrpcException(status\u001B[38;5;241m.\u001B[39mmessage) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m   2157\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_ALREADY_EXISTS] Cannot create table or view `deltaschema`.`deltatable` because it already exists.\n",
       "Choose a different name, drop the existing object, add the IF NOT EXISTS clause to tolerate pre-existing objects, add the OR REPLACE clause to replace the existing materialized view, or add the OR REFRESH clause to refresh the existing streaming table. SQLSTATE: 42P07\n",
       "\n",
       "JVM stacktrace:\n",
       "org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException\n",
       "\tat org.apache.spark.sql.errors.QueryCompilationErrors$.tableAlreadyExistsError(QueryCompilationErrors.scala:2189)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:66)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$2(V2CommandExec.scala:48)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:194)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:48)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:56)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:450)\n",
       "\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:450)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:216)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:449)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:477)\n",
       "\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:413)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:776)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:343)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:212)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:713)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:445)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1308)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:441)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:370)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:439)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:503)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:498)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:521)\n",
       "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:521)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:497)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:498)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:498)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:326)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n",
       "\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1745)\n",
       "\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:331)\n",
       "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:406)\n",
       "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$3(Dataset.scala:150)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1457)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1457)\n",
       "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:141)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1130)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1082)\n",
       "\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.executeSQL(SparkConnectPlanner.scala:3606)\n",
       "\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleSqlCommand(SparkConnectPlanner.scala:3435)\n",
       "\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3370)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:413)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:312)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:233)\n",
       "\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:464)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n",
       "\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:464)\n",
       "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)\n",
       "\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:90)\n",
       "\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:241)\n",
       "\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:89)\n",
       "\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:463)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:233)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:139)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.$anonfun$run$2(ExecuteThreadRunner.scala:614)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n",
       "\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n",
       "\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)\n",
       "\tat scala.util.Using$.resource(Using.scala:269)\n",
       "\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:614)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[TABLE_OR_VIEW_ALREADY_EXISTS] Cannot create table or view `deltaschema`.`deltatable` because it already exists.\nChoose a different name, drop the existing object, add the IF NOT EXISTS clause to tolerate pre-existing objects, add the OR REPLACE clause to replace the existing materialized view, or add the OR REFRESH clause to refresh the existing streaming table. SQLSTATE: 42P07\n\nJVM stacktrace:\norg.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException\n\tat org.apache.spark.sql.errors.QueryCompilationErrors$.tableAlreadyExistsError(QueryCompilationErrors.scala:2189)\n\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:66)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$2(V2CommandExec.scala:48)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:194)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:48)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:450)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:450)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:216)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:449)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:477)\n\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:413)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:776)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:343)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:212)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:713)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:445)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1308)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:441)\n\tat org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:370)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:439)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:503)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:498)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:497)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:498)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:498)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:326)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1745)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:331)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:406)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$3(Dataset.scala:150)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1457)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1457)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:141)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1130)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1082)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.executeSQL(SparkConnectPlanner.scala:3606)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleSqlCommand(SparkConnectPlanner.scala:3435)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3370)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:413)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:312)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:464)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:464)\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:90)\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:241)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:89)\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:463)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:139)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.$anonfun$run$2(ExecuteThreadRunner.scala:614)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)\n\tat scala.util.Using$.resource(Using.scala:269)\n\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:614)"
       },
       "metadata": {
        "errorSummary": "[TABLE_OR_VIEW_ALREADY_EXISTS] Cannot create table or view `deltaschema`.`deltatable` because it already exists.\nChoose a different name, drop the existing object, add the IF NOT EXISTS clause to tolerate pre-existing objects, add the OR REPLACE clause to replace the existing materialized view, or add the OR REFRESH clause to refresh the existing streaming table. SQLSTATE: 42P07"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "TABLE_OR_VIEW_ALREADY_EXISTS",
        "pysparkCallSite": "",
        "pysparkFragment": "",
        "pysparkSummary": null,
        "sqlState": "42P07",
        "stackTrace": "org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException\n\tat org.apache.spark.sql.errors.QueryCompilationErrors$.tableAlreadyExistsError(QueryCompilationErrors.scala:2189)\n\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:66)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$2(V2CommandExec.scala:48)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:194)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:48)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:450)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:450)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:216)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:449)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:477)\n\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:413)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:776)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:343)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:212)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:713)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:445)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1308)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:441)\n\tat org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:370)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:439)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:503)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:498)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:497)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:498)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:498)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:326)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1745)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:331)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:406)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$3(Dataset.scala:150)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1457)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1457)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:141)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1130)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1082)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.executeSQL(SparkConnectPlanner.scala:3606)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleSqlCommand(SparkConnectPlanner.scala:3435)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3370)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:413)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:312)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:464)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:464)\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:90)\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:241)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:89)\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:463)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:139)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.$anonfun$run$2(ExecuteThreadRunner.scala:614)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)\n\tat scala.util.Using$.resource(Using.scala:269)\n\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:614)",
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-5945745070037240>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_cell_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msql\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcreate table delta.deltaschema.deltatable\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m(\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  id int not null,\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  name string,\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  age int\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124musing delta\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2541\u001B[0m, in \u001B[0;36mInteractiveShell.run_cell_magic\u001B[0;34m(self, magic_name, line, cell)\u001B[0m\n\u001B[1;32m   2539\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m   2540\u001B[0m     args \u001B[38;5;241m=\u001B[39m (magic_arg_s, cell)\n\u001B[0;32m-> 2541\u001B[0m     result \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   2543\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[1;32m   2544\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[1;32m   2545\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[1;32m   2546\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:147\u001B[0m, in \u001B[0;36mSqlMagic.sql\u001B[0;34m(self, line, cell)\u001B[0m\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n\u001B[1;32m    144\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot run \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124mql command because spark connect initialization failed and no stacktrace was available.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    145\u001B[0m     )\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_py4j:\n\u001B[0;32m--> 147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexecute_via_py4j(cell)\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexecute_via_sql_comm_handler(cell)\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:231\u001B[0m, in \u001B[0;36mSqlMagic.execute_via_py4j\u001B[0;34m(self, cell)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdriver_activity_logger\u001B[38;5;241m.\u001B[39mlogExecuteCommandEvent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSQL_MAGIC_PY4J_FAILED\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    230\u001B[0m                                                        json\u001B[38;5;241m.\u001B[39mdumps(get_debug_info(e)))\n\u001B[0;32m--> 231\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdriver_activity_logger\u001B[38;5;241m.\u001B[39mlogExecuteCommandEvent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSQL_MAGIC_PY4J_SUCCEEDED\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:227\u001B[0m, in \u001B[0;36mSqlMagic.execute_via_py4j\u001B[0;34m(self, cell)\u001B[0m\n\u001B[1;32m    225\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecuting subquery: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquery_text\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, file\u001B[38;5;241m=\u001B[39msys\u001B[38;5;241m.\u001B[39m__stdout__)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    226\u001B[0m         sql_directive \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentry_point\u001B[38;5;241m.\u001B[39mgetSqlDirective(query_text)\n\u001B[0;32m--> 227\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_sql_directive(sql_directive, i \u001B[38;5;241m==\u001B[39m number_of_sub_queries \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdriver_activity_logger\u001B[38;5;241m.\u001B[39mlogExecuteCommandEvent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSQL_MAGIC_PY4J_FAILED\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    230\u001B[0m                                                        json\u001B[38;5;241m.\u001B[39mdumps(get_debug_info(e)))\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:249\u001B[0m, in \u001B[0;36mSqlMagic.handle_sql_directive\u001B[0;34m(self, sql_directive, is_last_query)\u001B[0m\n\u001B[1;32m    247\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_query_request_result(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSELECT * FROM \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtable_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    248\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m directive_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNoDirective\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 249\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_query_request_result(sql_directive\u001B[38;5;241m.\u001B[39msql())\n\u001B[1;32m    250\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m df \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(df\u001B[38;5;241m.\u001B[39mschema) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    251\u001B[0m         \u001B[38;5;66;03m# E.g. \"create or replace temp view abc as select 1\" gets us here and we should not return a result in this case.\u001B[39;00m\n\u001B[1;32m    252\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/sql_magic/sql_magic.py:124\u001B[0m, in \u001B[0;36mSqlMagic.get_query_request_result\u001B[0;34m(self, query)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(widget_bindings \u001B[38;5;241m:=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdbutils\u001B[38;5;241m.\u001B[39mwidgets\u001B[38;5;241m.\u001B[39mgetAll()) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    123\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdriver_activity_logger\u001B[38;5;241m.\u001B[39mlogExecuteCommandEvent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPARAM_SYNTAX_USAGE\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 124\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39masserting_spark\u001B[38;5;241m.\u001B[39msql(query, widget_bindings)\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/session.py:736\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n\u001B[1;32m    733\u001B[0m         _views\u001B[38;5;241m.\u001B[39mappend(SubqueryAlias(df\u001B[38;5;241m.\u001B[39m_plan, name))\n\u001B[1;32m    735\u001B[0m cmd \u001B[38;5;241m=\u001B[39m SQL(sqlQuery, _args, _named_args, _views)\n\u001B[0;32m--> 736\u001B[0m data, properties, ei \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mexecute_command(cmd\u001B[38;5;241m.\u001B[39mcommand(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client))\n\u001B[1;32m    737\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msql_command_result\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m properties:\n\u001B[1;32m    738\u001B[0m     df \u001B[38;5;241m=\u001B[39m DataFrame(CachedRelation(properties[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msql_command_result\u001B[39m\u001B[38;5;124m\"\u001B[39m]), \u001B[38;5;28mself\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1297\u001B[0m, in \u001B[0;36mSparkConnectClient.execute_command\u001B[0;34m(self, command, observations, extra_request_metadata)\u001B[0m\n\u001B[1;32m   1295\u001B[0m     req\u001B[38;5;241m.\u001B[39muser_context\u001B[38;5;241m.\u001B[39muser_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_user_id\n\u001B[1;32m   1296\u001B[0m req\u001B[38;5;241m.\u001B[39mplan\u001B[38;5;241m.\u001B[39mcommand\u001B[38;5;241m.\u001B[39mCopyFrom(command)\n\u001B[0;32m-> 1297\u001B[0m data, _, metrics, observed_metrics, properties \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_and_fetch(\n\u001B[1;32m   1298\u001B[0m     req, observations \u001B[38;5;129;01mor\u001B[39;00m {}, extra_request_metadata\n\u001B[1;32m   1299\u001B[0m )\n\u001B[1;32m   1300\u001B[0m \u001B[38;5;66;03m# Create a query execution object.\u001B[39;00m\n\u001B[1;32m   1301\u001B[0m ei \u001B[38;5;241m=\u001B[39m ExecutionInfo(metrics, observed_metrics)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1755\u001B[0m, in \u001B[0;36mSparkConnectClient._execute_and_fetch\u001B[0;34m(self, req, observations, extra_request_metadata, self_destruct)\u001B[0m\n\u001B[1;32m   1752\u001B[0m properties: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m   1754\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Progress(handlers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_progress_handlers, operation_id\u001B[38;5;241m=\u001B[39mreq\u001B[38;5;241m.\u001B[39moperation_id) \u001B[38;5;28;01mas\u001B[39;00m progress:\n\u001B[0;32m-> 1755\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m response \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_and_fetch_as_iterator(\n\u001B[1;32m   1756\u001B[0m         req, observations, extra_request_metadata \u001B[38;5;129;01mor\u001B[39;00m [], progress\u001B[38;5;241m=\u001B[39mprogress\n\u001B[1;32m   1757\u001B[0m     ):\n\u001B[1;32m   1758\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, StructType):\n\u001B[1;32m   1759\u001B[0m             schema \u001B[38;5;241m=\u001B[39m response\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1731\u001B[0m, in \u001B[0;36mSparkConnectClient._execute_and_fetch_as_iterator\u001B[0;34m(self, req, observations, extra_request_metadata, progress)\u001B[0m\n\u001B[1;32m   1729\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m kb\n\u001B[1;32m   1730\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[0;32m-> 1731\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_error(error)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:2047\u001B[0m, in \u001B[0;36mSparkConnectClient._handle_error\u001B[0;34m(self, error)\u001B[0m\n\u001B[1;32m   2045\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mthread_local\u001B[38;5;241m.\u001B[39minside_error_handling \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   2046\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(error, grpc\u001B[38;5;241m.\u001B[39mRpcError):\n\u001B[0;32m-> 2047\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_rpc_error(error)\n\u001B[1;32m   2048\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(error, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   2049\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot invoke RPC\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(error) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(error):\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:2149\u001B[0m, in \u001B[0;36mSparkConnectClient._handle_rpc_error\u001B[0;34m(self, rpc_error)\u001B[0m\n\u001B[1;32m   2134\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n\u001B[1;32m   2135\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPython versions in the Spark Connect client and server are different. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2136\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo execute user-defined functions, client and server should have the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2145\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://docs.databricks.com/en/release-notes/serverless.html.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2146\u001B[0m                 )\n\u001B[1;32m   2147\u001B[0m             \u001B[38;5;66;03m# END-EDGE\u001B[39;00m\n\u001B[0;32m-> 2149\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m convert_exception(\n\u001B[1;32m   2150\u001B[0m                 info,\n\u001B[1;32m   2151\u001B[0m                 status\u001B[38;5;241m.\u001B[39mmessage,\n\u001B[1;32m   2152\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fetch_enriched_error(info),\n\u001B[1;32m   2153\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_display_server_stack_trace(),\n\u001B[1;32m   2154\u001B[0m             ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   2156\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m SparkConnectGrpcException(status\u001B[38;5;241m.\u001B[39mmessage) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   2157\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_ALREADY_EXISTS] Cannot create table or view `deltaschema`.`deltatable` because it already exists.\nChoose a different name, drop the existing object, add the IF NOT EXISTS clause to tolerate pre-existing objects, add the OR REPLACE clause to replace the existing materialized view, or add the OR REFRESH clause to refresh the existing streaming table. SQLSTATE: 42P07\n\nJVM stacktrace:\norg.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException\n\tat org.apache.spark.sql.errors.QueryCompilationErrors$.tableAlreadyExistsError(QueryCompilationErrors.scala:2189)\n\tat org.apache.spark.sql.execution.datasources.v2.CreateTableExec.run(CreateTableExec.scala:66)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$2(V2CommandExec.scala:48)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:194)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:48)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:450)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:450)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:216)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:449)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:477)\n\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:413)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:776)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:343)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:212)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:713)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:445)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1308)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:441)\n\tat org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:370)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:439)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:503)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:498)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:497)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:498)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:498)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:326)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1745)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:331)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:406)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$3(Dataset.scala:150)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1457)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1457)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:141)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1130)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1082)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.executeSQL(SparkConnectPlanner.scala:3606)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleSqlCommand(SparkConnectPlanner.scala:3435)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3370)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:413)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:312)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:464)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:464)\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:90)\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:241)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:89)\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:463)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:139)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.$anonfun$run$2(ExecuteThreadRunner.scala:614)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)\n\tat scala.util.Using$.resource(Using.scala:269)\n\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:614)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "create table delta.deltaschema.deltatable\n",
    "(\n",
    "  id int not null,\n",
    "  name string,\n",
    "  age int\n",
    ")\n",
    "using delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c511bae-4b46-4e7c-a49f-4100b2d8ea24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## insert values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e10ae3a-33c9-45ae-80f4-3cf9784a8efa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody><tr><td>4</td><td>4</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         4,
         4
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "num_affected_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_inserted_rows",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 89
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "insert into delta.deltaschema.deltatable(id,name,age) values\n",
    "(1,\"suresh\",25),\n",
    "(2,\"kumar\",30),\n",
    "(3,\"ram\",35),\n",
    "(4,\"murugan\",40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89f5247a-f3ae-466c-831f-f5cd3eb49ceb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "369b7469-a604-46b6-bba6-20cc45b62c30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from delta.deltaschema.deltatable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e986cfa6-1ce6-4cac-9e55-2e987998c2b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8a2fc7e-77b2-4826-b8ff-cfe5c2fd0faf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>age</th></tr></thead><tbody><tr><td>1</td><td>John</td><td>25</td></tr><tr><td>2</td><td>Smith</td><td>30</td></tr><tr><td>3</td><td>Sarah</td><td>35</td></tr><tr><td>4</td><td>Mary</td><td>40</td></tr><tr><td>5</td><td>Mike</td><td>45</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "John",
         25
        ],
        [
         2,
         "Smith",
         30
        ],
        [
         3,
         "Sarah",
         35
        ],
        [
         4,
         "Mary",
         40
        ],
        [
         5,
         "Mike",
         45
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [(1, 'John',25),(2, 'Smith',30),(3, 'Sarah',35),(4, 'Mary',40),(5, 'Mike',45)]\n",
    "\n",
    "\n",
    "schema = ['id', 'name', 'age']\n",
    "\n",
    "df = spark.createDataFrame(data,schema)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc50945d-49a2-4683-9cb6-d17a271f1d05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c325494-2e77-418e-a9a0-a2844aca84c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-5945745070037255>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m df\u001B[38;5;241m.\u001B[39mwrite\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelta\u001B[39m\u001B[38;5;124m\"\u001B[39m)\\\n",
       "\u001B[1;32m      2\u001B[0m     \u001B[38;5;241m.\u001B[39mmode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mappend\u001B[39m\u001B[38;5;124m\"\u001B[39m)\\\n",
       "\u001B[0;32m----> 3\u001B[0m         \u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/Volumes/delta/deltaschema/sink\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/readwriter.py:679\u001B[0m, in \u001B[0;36mDataFrameWriter.save\u001B[0;34m(self, path, format, mode, partitionBy, **options)\u001B[0m\n",
       "\u001B[1;32m    677\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mformat\u001B[39m)\n",
       "\u001B[1;32m    678\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_write\u001B[38;5;241m.\u001B[39mpath \u001B[38;5;241m=\u001B[39m path\n",
       "\u001B[0;32m--> 679\u001B[0m _, _, ei \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_spark\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mexecute_command(\n",
       "\u001B[1;32m    680\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_write\u001B[38;5;241m.\u001B[39mcommand(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_spark\u001B[38;5;241m.\u001B[39mclient), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_write\u001B[38;5;241m.\u001B[39mobservations\n",
       "\u001B[1;32m    681\u001B[0m )\n",
       "\u001B[1;32m    682\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callback(ei)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1297\u001B[0m, in \u001B[0;36mSparkConnectClient.execute_command\u001B[0;34m(self, command, observations, extra_request_metadata)\u001B[0m\n",
       "\u001B[1;32m   1295\u001B[0m     req\u001B[38;5;241m.\u001B[39muser_context\u001B[38;5;241m.\u001B[39muser_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_user_id\n",
       "\u001B[1;32m   1296\u001B[0m req\u001B[38;5;241m.\u001B[39mplan\u001B[38;5;241m.\u001B[39mcommand\u001B[38;5;241m.\u001B[39mCopyFrom(command)\n",
       "\u001B[0;32m-> 1297\u001B[0m data, _, metrics, observed_metrics, properties \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_and_fetch(\n",
       "\u001B[1;32m   1298\u001B[0m     req, observations \u001B[38;5;129;01mor\u001B[39;00m {}, extra_request_metadata\n",
       "\u001B[1;32m   1299\u001B[0m )\n",
       "\u001B[1;32m   1300\u001B[0m \u001B[38;5;66;03m# Create a query execution object.\u001B[39;00m\n",
       "\u001B[1;32m   1301\u001B[0m ei \u001B[38;5;241m=\u001B[39m ExecutionInfo(metrics, observed_metrics)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1755\u001B[0m, in \u001B[0;36mSparkConnectClient._execute_and_fetch\u001B[0;34m(self, req, observations, extra_request_metadata, self_destruct)\u001B[0m\n",
       "\u001B[1;32m   1752\u001B[0m properties: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m {}\n",
       "\u001B[1;32m   1754\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Progress(handlers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_progress_handlers, operation_id\u001B[38;5;241m=\u001B[39mreq\u001B[38;5;241m.\u001B[39moperation_id) \u001B[38;5;28;01mas\u001B[39;00m progress:\n",
       "\u001B[0;32m-> 1755\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m response \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_and_fetch_as_iterator(\n",
       "\u001B[1;32m   1756\u001B[0m         req, observations, extra_request_metadata \u001B[38;5;129;01mor\u001B[39;00m [], progress\u001B[38;5;241m=\u001B[39mprogress\n",
       "\u001B[1;32m   1757\u001B[0m     ):\n",
       "\u001B[1;32m   1758\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, StructType):\n",
       "\u001B[1;32m   1759\u001B[0m             schema \u001B[38;5;241m=\u001B[39m response\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1731\u001B[0m, in \u001B[0;36mSparkConnectClient._execute_and_fetch_as_iterator\u001B[0;34m(self, req, observations, extra_request_metadata, progress)\u001B[0m\n",
       "\u001B[1;32m   1729\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m kb\n",
       "\u001B[1;32m   1730\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n",
       "\u001B[0;32m-> 1731\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_error(error)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:2047\u001B[0m, in \u001B[0;36mSparkConnectClient._handle_error\u001B[0;34m(self, error)\u001B[0m\n",
       "\u001B[1;32m   2045\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mthread_local\u001B[38;5;241m.\u001B[39minside_error_handling \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[1;32m   2046\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(error, grpc\u001B[38;5;241m.\u001B[39mRpcError):\n",
       "\u001B[0;32m-> 2047\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_rpc_error(error)\n",
       "\u001B[1;32m   2048\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(error, \u001B[38;5;167;01mValueError\u001B[39;00m):\n",
       "\u001B[1;32m   2049\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot invoke RPC\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(error) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(error):\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:2149\u001B[0m, in \u001B[0;36mSparkConnectClient._handle_rpc_error\u001B[0;34m(self, rpc_error)\u001B[0m\n",
       "\u001B[1;32m   2134\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n",
       "\u001B[1;32m   2135\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPython versions in the Spark Connect client and server are different. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   2136\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo execute user-defined functions, client and server should have the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   2145\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://docs.databricks.com/en/release-notes/serverless.html.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   2146\u001B[0m                 )\n",
       "\u001B[1;32m   2147\u001B[0m             \u001B[38;5;66;03m# END-EDGE\u001B[39;00m\n",
       "\u001B[0;32m-> 2149\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m convert_exception(\n",
       "\u001B[1;32m   2150\u001B[0m                 info,\n",
       "\u001B[1;32m   2151\u001B[0m                 status\u001B[38;5;241m.\u001B[39mmessage,\n",
       "\u001B[1;32m   2152\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fetch_enriched_error(info),\n",
       "\u001B[1;32m   2153\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_display_server_stack_trace(),\n",
       "\u001B[1;32m   2154\u001B[0m             ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m   2156\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m SparkConnectGrpcException(status\u001B[38;5;241m.\u001B[39mmessage) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m   2157\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [_LEGACY_ERROR_TEMP_DELTA_0007] A schema mismatch detected when writing to the Delta table (Table ID: 9d21597c-3872-4546-8410-2577220ea023).\n",
       "To enable schema migration using DataFrameWriter or DataStreamWriter, please set:\n",
       "'.option(\"mergeSchema\", \"true\")'.\n",
       "For other operations, set the session configuration\n",
       "spark.databricks.delta.schema.autoMerge.enabled to \"true\". See the documentation\n",
       "specific to the operation for details.\n",
       "\n",
       "Table schema:\n",
       "root\n",
       "-- cust_id: long (nullable = true)\n",
       "-- cust_name: string (nullable = true)\n",
       "-- cust_age: long (nullable = true)\n",
       "-- cust_city: string (nullable = true)\n",
       "\n",
       "\n",
       "Data schema:\n",
       "root\n",
       "-- id: long (nullable = true)\n",
       "-- name: string (nullable = true)\n",
       "-- age: long (nullable = true)\n",
       "\n",
       "         \n",
       "Table ACLs are enabled in this cluster, so automatic schema migration is not allowed. Please use the ALTER TABLE command for changing the schema.         \n",
       "\n",
       "JVM stacktrace:\n",
       "com.databricks.sql.transaction.tahoe.DeltaAnalysisException\n",
       "\tat com.databricks.sql.transaction.tahoe.MetadataMismatchErrorBuilder.finalizeAndThrow(DeltaErrors.scala:4154)\n",
       "\tat com.databricks.sql.transaction.tahoe.schema.ImplicitMetadataOperation.updateMetadata(ImplicitMetadataOperation.scala:230)\n",
       "\tat com.databricks.sql.transaction.tahoe.schema.ImplicitMetadataOperation.updateMetadata$(ImplicitMetadataOperation.scala:91)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.updateMetadata(WriteIntoDeltaEdge.scala:111)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeAndReturnCommitDataAndMaterializationPlans(WriteIntoDeltaEdge.scala:313)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeAndReturnCommitData(WriteIntoDeltaEdge.scala:209)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$2(WriteIntoDeltaEdge.scala:155)\n",
       "\tat com.databricks.sql.transaction.tahoe.DeltaLog.withNewTransaction(DeltaLog.scala:302)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$1(WriteIntoDeltaEdge.scala:142)\n",
       "\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2432)\n",
       "\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:63)\n",
       "\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:60)\n",
       "\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:212)\n",
       "\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2432)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.run(WriteIntoDeltaEdge.scala:141)\n",
       "\tat com.databricks.sql.transaction.tahoe.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:286)\n",
       "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:55)\n",
       "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:84)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:194)\n",
       "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:84)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:81)\n",
       "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:80)\n",
       "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:94)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:450)\n",
       "\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:450)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:216)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:449)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:477)\n",
       "\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:413)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:776)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:343)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:212)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:713)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:445)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1308)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:441)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:370)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:439)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:503)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:498)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:521)\n",
       "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:521)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:497)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:498)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:498)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:326)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n",
       "\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1745)\n",
       "\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:331)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:528)\n",
       "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:1164)\n",
       "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:492)\n",
       "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:384)\n",
       "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:301)\n",
       "\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteOperation(SparkConnectPlanner.scala:3869)\n",
       "\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3362)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:413)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:312)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:233)\n",
       "\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:464)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n",
       "\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:464)\n",
       "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)\n",
       "\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:90)\n",
       "\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:241)\n",
       "\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:89)\n",
       "\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:463)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:233)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:139)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.$anonfun$run$2(ExecuteThreadRunner.scala:614)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n",
       "\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n",
       "\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)\n",
       "\tat scala.util.Using$.resource(Using.scala:269)\n",
       "\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)\n",
       "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:614)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[_LEGACY_ERROR_TEMP_DELTA_0007] A schema mismatch detected when writing to the Delta table (Table ID: 9d21597c-3872-4546-8410-2577220ea023).\nTo enable schema migration using DataFrameWriter or DataStreamWriter, please set:\n'.option(\"mergeSchema\", \"true\")'.\nFor other operations, set the session configuration\nspark.databricks.delta.schema.autoMerge.enabled to \"true\". See the documentation\nspecific to the operation for details.\n\nTable schema:\nroot\n-- cust_id: long (nullable = true)\n-- cust_name: string (nullable = true)\n-- cust_age: long (nullable = true)\n-- cust_city: string (nullable = true)\n\n\nData schema:\nroot\n-- id: long (nullable = true)\n-- name: string (nullable = true)\n-- age: long (nullable = true)\n\n         \nTable ACLs are enabled in this cluster, so automatic schema migration is not allowed. Please use the ALTER TABLE command for changing the schema.         \n\nJVM stacktrace:\ncom.databricks.sql.transaction.tahoe.DeltaAnalysisException\n\tat com.databricks.sql.transaction.tahoe.MetadataMismatchErrorBuilder.finalizeAndThrow(DeltaErrors.scala:4154)\n\tat com.databricks.sql.transaction.tahoe.schema.ImplicitMetadataOperation.updateMetadata(ImplicitMetadataOperation.scala:230)\n\tat com.databricks.sql.transaction.tahoe.schema.ImplicitMetadataOperation.updateMetadata$(ImplicitMetadataOperation.scala:91)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.updateMetadata(WriteIntoDeltaEdge.scala:111)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeAndReturnCommitDataAndMaterializationPlans(WriteIntoDeltaEdge.scala:313)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeAndReturnCommitData(WriteIntoDeltaEdge.scala:209)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$2(WriteIntoDeltaEdge.scala:155)\n\tat com.databricks.sql.transaction.tahoe.DeltaLog.withNewTransaction(DeltaLog.scala:302)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$1(WriteIntoDeltaEdge.scala:142)\n\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2432)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:63)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:60)\n\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:212)\n\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2432)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.run(WriteIntoDeltaEdge.scala:141)\n\tat com.databricks.sql.transaction.tahoe.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:286)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:55)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:84)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:194)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:84)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:81)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:80)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:94)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:450)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:450)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:216)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:449)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:477)\n\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:413)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:776)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:343)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:212)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:713)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:445)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1308)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:441)\n\tat org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:370)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:439)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:503)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:498)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:497)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:498)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:498)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:326)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1745)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:331)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:528)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:1164)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:492)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:384)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:301)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteOperation(SparkConnectPlanner.scala:3869)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3362)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:413)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:312)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:464)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:464)\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:90)\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:241)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:89)\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:463)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:139)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.$anonfun$run$2(ExecuteThreadRunner.scala:614)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)\n\tat scala.util.Using$.resource(Using.scala:269)\n\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:614)"
       },
       "metadata": {
        "errorSummary": "A schema mismatch detected when writing to the Delta table (Table ID: 9d21597c-3872-4546-8410-2577220ea023).\nTo enable schema migration using DataFrameWriter or DataStreamWriter, please set:\n'.option(\"mergeSchema\", \"true\")'.\nFor other operations, set the session configuration\nspark.databricks.delta.schema.autoMerge.enabled to \"true\". See the documentation\nspecific to the operation for details.\n\nTable schema:\nroot\n-- cust_id: long (nullable = true)\n-- cust_name: string (nullable = true)\n-- cust_age: long (nullable = true)\n-- cust_city: string (nullable = true)\n\n\nData schema:\nroot\n-- id: long (nullable = true)\n-- name: string (nullable = true)\n-- age: long (nullable = true)\n\n         \nTable ACLs are enabled in this cluster, so automatic schema migration is not allowed. Please use the ALTER TABLE command for changing the schema.         "
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "_LEGACY_ERROR_TEMP_DELTA_0007",
        "pysparkCallSite": "",
        "pysparkFragment": "",
        "pysparkSummary": null,
        "sqlState": null,
        "stackTrace": "com.databricks.sql.transaction.tahoe.DeltaAnalysisException\n\tat com.databricks.sql.transaction.tahoe.MetadataMismatchErrorBuilder.finalizeAndThrow(DeltaErrors.scala:4154)\n\tat com.databricks.sql.transaction.tahoe.schema.ImplicitMetadataOperation.updateMetadata(ImplicitMetadataOperation.scala:230)\n\tat com.databricks.sql.transaction.tahoe.schema.ImplicitMetadataOperation.updateMetadata$(ImplicitMetadataOperation.scala:91)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.updateMetadata(WriteIntoDeltaEdge.scala:111)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeAndReturnCommitDataAndMaterializationPlans(WriteIntoDeltaEdge.scala:313)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeAndReturnCommitData(WriteIntoDeltaEdge.scala:209)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$2(WriteIntoDeltaEdge.scala:155)\n\tat com.databricks.sql.transaction.tahoe.DeltaLog.withNewTransaction(DeltaLog.scala:302)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$1(WriteIntoDeltaEdge.scala:142)\n\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2432)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:63)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:60)\n\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:212)\n\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2432)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.run(WriteIntoDeltaEdge.scala:141)\n\tat com.databricks.sql.transaction.tahoe.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:286)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:55)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:84)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:194)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:84)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:81)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:80)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:94)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:450)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:450)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:216)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:449)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:477)\n\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:413)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:776)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:343)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:212)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:713)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:445)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1308)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:441)\n\tat org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:370)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:439)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:503)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:498)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:497)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:498)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:498)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:326)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1745)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:331)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:528)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:1164)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:492)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:384)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:301)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteOperation(SparkConnectPlanner.scala:3869)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3362)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:413)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:312)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:464)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:464)\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:90)\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:241)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:89)\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:463)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:139)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.$anonfun$run$2(ExecuteThreadRunner.scala:614)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)\n\tat scala.util.Using$.resource(Using.scala:269)\n\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:614)",
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-5945745070037255>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m df\u001B[38;5;241m.\u001B[39mwrite\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelta\u001B[39m\u001B[38;5;124m\"\u001B[39m)\\\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;241m.\u001B[39mmode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mappend\u001B[39m\u001B[38;5;124m\"\u001B[39m)\\\n\u001B[0;32m----> 3\u001B[0m         \u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/Volumes/delta/deltaschema/sink\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/readwriter.py:679\u001B[0m, in \u001B[0;36mDataFrameWriter.save\u001B[0;34m(self, path, format, mode, partitionBy, **options)\u001B[0m\n\u001B[1;32m    677\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mformat\u001B[39m)\n\u001B[1;32m    678\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_write\u001B[38;5;241m.\u001B[39mpath \u001B[38;5;241m=\u001B[39m path\n\u001B[0;32m--> 679\u001B[0m _, _, ei \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_spark\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mexecute_command(\n\u001B[1;32m    680\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_write\u001B[38;5;241m.\u001B[39mcommand(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_spark\u001B[38;5;241m.\u001B[39mclient), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_write\u001B[38;5;241m.\u001B[39mobservations\n\u001B[1;32m    681\u001B[0m )\n\u001B[1;32m    682\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callback(ei)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1297\u001B[0m, in \u001B[0;36mSparkConnectClient.execute_command\u001B[0;34m(self, command, observations, extra_request_metadata)\u001B[0m\n\u001B[1;32m   1295\u001B[0m     req\u001B[38;5;241m.\u001B[39muser_context\u001B[38;5;241m.\u001B[39muser_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_user_id\n\u001B[1;32m   1296\u001B[0m req\u001B[38;5;241m.\u001B[39mplan\u001B[38;5;241m.\u001B[39mcommand\u001B[38;5;241m.\u001B[39mCopyFrom(command)\n\u001B[0;32m-> 1297\u001B[0m data, _, metrics, observed_metrics, properties \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_and_fetch(\n\u001B[1;32m   1298\u001B[0m     req, observations \u001B[38;5;129;01mor\u001B[39;00m {}, extra_request_metadata\n\u001B[1;32m   1299\u001B[0m )\n\u001B[1;32m   1300\u001B[0m \u001B[38;5;66;03m# Create a query execution object.\u001B[39;00m\n\u001B[1;32m   1301\u001B[0m ei \u001B[38;5;241m=\u001B[39m ExecutionInfo(metrics, observed_metrics)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1755\u001B[0m, in \u001B[0;36mSparkConnectClient._execute_and_fetch\u001B[0;34m(self, req, observations, extra_request_metadata, self_destruct)\u001B[0m\n\u001B[1;32m   1752\u001B[0m properties: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m   1754\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Progress(handlers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_progress_handlers, operation_id\u001B[38;5;241m=\u001B[39mreq\u001B[38;5;241m.\u001B[39moperation_id) \u001B[38;5;28;01mas\u001B[39;00m progress:\n\u001B[0;32m-> 1755\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m response \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_and_fetch_as_iterator(\n\u001B[1;32m   1756\u001B[0m         req, observations, extra_request_metadata \u001B[38;5;129;01mor\u001B[39;00m [], progress\u001B[38;5;241m=\u001B[39mprogress\n\u001B[1;32m   1757\u001B[0m     ):\n\u001B[1;32m   1758\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, StructType):\n\u001B[1;32m   1759\u001B[0m             schema \u001B[38;5;241m=\u001B[39m response\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1731\u001B[0m, in \u001B[0;36mSparkConnectClient._execute_and_fetch_as_iterator\u001B[0;34m(self, req, observations, extra_request_metadata, progress)\u001B[0m\n\u001B[1;32m   1729\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m kb\n\u001B[1;32m   1730\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[0;32m-> 1731\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_error(error)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:2047\u001B[0m, in \u001B[0;36mSparkConnectClient._handle_error\u001B[0;34m(self, error)\u001B[0m\n\u001B[1;32m   2045\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mthread_local\u001B[38;5;241m.\u001B[39minside_error_handling \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   2046\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(error, grpc\u001B[38;5;241m.\u001B[39mRpcError):\n\u001B[0;32m-> 2047\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_rpc_error(error)\n\u001B[1;32m   2048\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(error, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   2049\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot invoke RPC\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(error) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(error):\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:2149\u001B[0m, in \u001B[0;36mSparkConnectClient._handle_rpc_error\u001B[0;34m(self, rpc_error)\u001B[0m\n\u001B[1;32m   2134\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n\u001B[1;32m   2135\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPython versions in the Spark Connect client and server are different. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2136\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo execute user-defined functions, client and server should have the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2145\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://docs.databricks.com/en/release-notes/serverless.html.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2146\u001B[0m                 )\n\u001B[1;32m   2147\u001B[0m             \u001B[38;5;66;03m# END-EDGE\u001B[39;00m\n\u001B[0;32m-> 2149\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m convert_exception(\n\u001B[1;32m   2150\u001B[0m                 info,\n\u001B[1;32m   2151\u001B[0m                 status\u001B[38;5;241m.\u001B[39mmessage,\n\u001B[1;32m   2152\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fetch_enriched_error(info),\n\u001B[1;32m   2153\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_display_server_stack_trace(),\n\u001B[1;32m   2154\u001B[0m             ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   2156\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m SparkConnectGrpcException(status\u001B[38;5;241m.\u001B[39mmessage) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   2157\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [_LEGACY_ERROR_TEMP_DELTA_0007] A schema mismatch detected when writing to the Delta table (Table ID: 9d21597c-3872-4546-8410-2577220ea023).\nTo enable schema migration using DataFrameWriter or DataStreamWriter, please set:\n'.option(\"mergeSchema\", \"true\")'.\nFor other operations, set the session configuration\nspark.databricks.delta.schema.autoMerge.enabled to \"true\". See the documentation\nspecific to the operation for details.\n\nTable schema:\nroot\n-- cust_id: long (nullable = true)\n-- cust_name: string (nullable = true)\n-- cust_age: long (nullable = true)\n-- cust_city: string (nullable = true)\n\n\nData schema:\nroot\n-- id: long (nullable = true)\n-- name: string (nullable = true)\n-- age: long (nullable = true)\n\n         \nTable ACLs are enabled in this cluster, so automatic schema migration is not allowed. Please use the ALTER TABLE command for changing the schema.         \n\nJVM stacktrace:\ncom.databricks.sql.transaction.tahoe.DeltaAnalysisException\n\tat com.databricks.sql.transaction.tahoe.MetadataMismatchErrorBuilder.finalizeAndThrow(DeltaErrors.scala:4154)\n\tat com.databricks.sql.transaction.tahoe.schema.ImplicitMetadataOperation.updateMetadata(ImplicitMetadataOperation.scala:230)\n\tat com.databricks.sql.transaction.tahoe.schema.ImplicitMetadataOperation.updateMetadata$(ImplicitMetadataOperation.scala:91)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.updateMetadata(WriteIntoDeltaEdge.scala:111)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeAndReturnCommitDataAndMaterializationPlans(WriteIntoDeltaEdge.scala:313)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeAndReturnCommitData(WriteIntoDeltaEdge.scala:209)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$2(WriteIntoDeltaEdge.scala:155)\n\tat com.databricks.sql.transaction.tahoe.DeltaLog.withNewTransaction(DeltaLog.scala:302)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$1(WriteIntoDeltaEdge.scala:142)\n\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2432)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:63)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:60)\n\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:212)\n\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2432)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.run(WriteIntoDeltaEdge.scala:141)\n\tat com.databricks.sql.transaction.tahoe.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:286)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:55)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:84)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:194)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:84)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:81)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:80)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:94)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:450)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:450)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:216)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:449)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:477)\n\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:413)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:776)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:343)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:212)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:713)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:445)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1308)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:441)\n\tat org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:370)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:439)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:503)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:498)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:497)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:498)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:498)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:326)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1745)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:331)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:528)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:1164)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:492)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:384)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:301)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteOperation(SparkConnectPlanner.scala:3869)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3362)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:413)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:312)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:464)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:464)\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:90)\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:241)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:89)\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:463)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:233)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:139)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.$anonfun$run$2(ExecuteThreadRunner.scala:614)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)\n\tat scala.util.Using$.resource(Using.scala:269)\n\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:614)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.write.format(\"delta\")\\\n",
    "    .mode(\"append\")\\\n",
    "        .save(\"/Volumes/delta/deltaschema/sink\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcfdc13c-efbc-4ea7-85d1-bfa72ab74a59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## read delta data that means parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98351f51-a9c4-46ff-a894-ed16e3580314",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>cust_id</th><th>cust_name</th><th>cust_age</th><th>cust_city</th></tr></thead><tbody><tr><td>1</td><td>John</td><td>25</td><td>chennai</td></tr><tr><td>2</td><td>Smith</td><td>30</td><td>salem</td></tr><tr><td>3</td><td>Sarah</td><td>35</td><td>covai</td></tr><tr><td>4</td><td>Mary</td><td>40</td><td>trichy</td></tr><tr><td>5</td><td>Mike</td><td>45</td><td>ooty</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "John",
         25,
         "chennai"
        ],
        [
         2,
         "Smith",
         30,
         "salem"
        ],
        [
         3,
         "Sarah",
         35,
         "covai"
        ],
        [
         4,
         "Mary",
         40,
         "trichy"
        ],
        [
         5,
         "Mike",
         45,
         "ooty"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "cust_id",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cust_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cust_age",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cust_city",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 92
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "cust_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cust_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cust_age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cust_city",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from delta.`/Volumes/delta/deltaschema/sink`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10db1e17-dfdc-4fb6-95e1-e4e3b63d374c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **SCHEMA ENFORCEMENT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "223c3980-796a-4edd-9d45-e9090382336d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1 = [(1, 'John',25,\"chennai\"),(2, 'Smith',30,\"salem\"),(3, 'Sarah',35,\"covai\"),(4, 'Mary',40,\"trichy\"),(5, 'Mike',45,\"ooty\")]\n",
    "\n",
    "\n",
    "schema1 = ['id','name','age','city']\n",
    "\n",
    "df1 = spark.createDataFrame(data1,schema1)\n",
    "\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81f66ed3-c948-4cc4-8a07-2879667da473",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## here i already append one data frame in /Volumes/delta/deltaschema/sink this location schema is ['id', 'name', 'age']  but now i add other dataframe with different schema ['id','name','age','city']  can't show error we use SCHEMA EVOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd5a99cb-73a2-4a6f-bc6f-f48e8d599855",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1.write.format(\"delta\")\\\n",
    "  .mode(\"append\")\\\n",
    "    .save(\"/Volumes/delta/deltaschema/sink\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75361e5c-4282-448a-bb11-8042b644f670",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **SCHEMA EVOLUTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6577383-69ca-475f-b85e-440f08e703e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1.write.format(\"delta\")\\\n",
    "    .mode(\"append\")\\\n",
    "    .option(\"mergeSchema\",\"true\")\\\n",
    "    .save(\"/Volumes/delta/deltaschema/sink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d00c673a-d807-4477-bc62-03aca123b23c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from delta.`/Volumes/delta/deltaschema/sink`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96ce4b8f-f2e9-4858-8dba-b9c4e44e30c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **SCHEMA OVERWRITE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "280897e7-13fb-4130-9a02-7028bf5cabc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## here now i change schema name above add new schema in dataframe and write same location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3108c083-6de5-4c32-b9f9-300a017a99d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data2 = [(1, 'John',25,\"chennai\"),(2, 'Smith',30,\"salem\"),(3, 'Sarah',35,\"covai\"),(4, 'Mary',40,\"trichy\"),(5, 'Mike',45,\"ooty\")]\n",
    "\n",
    "\n",
    "schema2 = ['cust_id','cust_name','cust_age','cust_city']\n",
    "\n",
    "df2 = spark.createDataFrame(data2,schema2)\n",
    "\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2f620f2-5046-4d71-92aa-a91f125b6f07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.write.format(\"delta\")\\\n",
    "    .mode(\"append\")\\\n",
    "    .save(\"/Volumes/delta/deltaschema/sink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f16bf3c-1d51-4308-af26-18e4f1eb4a22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.write.format(\"delta\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save(\"/Volumes/delta/deltaschema/sink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2179116-26d5-4353-b26b-fe57dd3924e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2.write.format(\"delta\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .option(\"overwriteSchema\",\"true\")\\\n",
    "    .save(\"/Volumes/delta/deltaschema/sink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4ebe5dc-b7e3-4ee8-8ecf-46e9e9c14975",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>cust_id</th><th>cust_name</th><th>cust_age</th><th>cust_city</th></tr></thead><tbody><tr><td>1</td><td>John</td><td>25</td><td>chennai</td></tr><tr><td>2</td><td>Smith</td><td>30</td><td>salem</td></tr><tr><td>3</td><td>Sarah</td><td>35</td><td>covai</td></tr><tr><td>4</td><td>Mary</td><td>40</td><td>trichy</td></tr><tr><td>5</td><td>Mike</td><td>45</td><td>ooty</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "John",
         25,
         "chennai"
        ],
        [
         2,
         "Smith",
         30,
         "salem"
        ],
        [
         3,
         "Sarah",
         35,
         "covai"
        ],
        [
         4,
         "Mary",
         40,
         "trichy"
        ],
        [
         5,
         "Mike",
         45,
         "ooty"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "cust_id",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cust_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cust_age",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cust_city",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 94
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "cust_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cust_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cust_age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cust_city",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from delta.`/Volumes/delta/deltaschema/sink`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bac74520-2577-4341-986e-88e4915d5508",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **DML**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2662cb94-4bf3-4b6e-acb4-41e8b51d07e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **update**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f036afe9-fdae-4a54-8706-9586363ad6cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th></tr></thead><tbody><tr><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "num_affected_rows",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 98
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "update delta.`/Volumes/delta/deltaschema/sink`\n",
    "set cust_name = \"john cena\"\n",
    "where cust_id = 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eb88113-9b82-4043-a2f3-47d4b176142e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>cust_id</th><th>cust_name</th><th>cust_age</th><th>cust_city</th></tr></thead><tbody><tr><td>1</td><td>john cena</td><td>25</td><td>chennai</td></tr><tr><td>2</td><td>Smith</td><td>30</td><td>salem</td></tr><tr><td>3</td><td>Sarah</td><td>35</td><td>covai</td></tr><tr><td>4</td><td>Mary</td><td>40</td><td>trichy</td></tr><tr><td>5</td><td>Mike</td><td>45</td><td>ooty</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "john cena",
         25,
         "chennai"
        ],
        [
         2,
         "Smith",
         30,
         "salem"
        ],
        [
         3,
         "Sarah",
         35,
         "covai"
        ],
        [
         4,
         "Mary",
         40,
         "trichy"
        ],
        [
         5,
         "Mike",
         45,
         "ooty"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "cust_id",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cust_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cust_age",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cust_city",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 99
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "cust_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cust_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cust_age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cust_city",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from delta.`/Volumes/delta/deltaschema/sink`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c60bdf5-1fa7-4fb2-818f-99d50976e7b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **UPSERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a44c43d4-205f-41fe-b72e-00129f5bc1cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>cust_id</th><th>cust_name</th><th>cust_age</th><th>cust_city</th></tr></thead><tbody><tr><td>6</td><td>aaaaa</td><td>25</td><td>chennai</td></tr><tr><td>2</td><td>Smithaaaaaa</td><td>30</td><td>salem</td></tr><tr><td>7</td><td>bbbb</td><td>35</td><td>covai</td></tr><tr><td>8</td><td>cccc</td><td>40</td><td>trichy</td></tr><tr><td>5</td><td>Mikeeeeeeee</td><td>45</td><td>ooty</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         6,
         "aaaaa",
         25,
         "chennai"
        ],
        [
         2,
         "Smithaaaaaa",
         30,
         "salem"
        ],
        [
         7,
         "bbbb",
         35,
         "covai"
        ],
        [
         8,
         "cccc",
         40,
         "trichy"
        ],
        [
         5,
         "Mikeeeeeeee",
         45,
         "ooty"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "cust_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cust_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cust_age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cust_city",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data3 = [(6, 'aaaaa',25,\"chennai\"),(2, 'Smithaaaaaa',30,\"salem\"),(7, 'bbbb',35,\"covai\"),(8, 'cccc',40,\"trichy\"),(5, 'Mikeeeeeeee',45,\"ooty\")]\n",
    "\n",
    "schema3 = ['cust_id','cust_name','cust_age','cust_city']\n",
    "\n",
    "df3 = spark.createDataFrame(data3,schema3)\n",
    "\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fcd76cc-f125-4ef1-a960-971633089f76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae1010c5-2e7c-4d85-8cb4-c25829c6d533",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlt_obj = DeltaTable.forPath(spark,\"/Volumes/delta/deltaschema/sink\")\n",
    "\n",
    "\n",
    "dlt_obj.alias(\"target\").merge(df3.alias(\"source\"), \"target.cust_id = source.cust_id\")\\\n",
    "    .whenMatchedUpdateAll()\\\n",
    "    .whenNotMatchedInsertAll()\\\n",
    "    .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87eb7ad9-94b0-4c64-a75b-c3362f54eb38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>cust_id</th><th>cust_name</th><th>cust_age</th><th>cust_city</th></tr></thead><tbody><tr><td>1</td><td>john cena</td><td>25</td><td>chennai</td></tr><tr><td>3</td><td>Sarah</td><td>35</td><td>covai</td></tr><tr><td>4</td><td>Mary</td><td>40</td><td>trichy</td></tr><tr><td>6</td><td>aaaaa</td><td>25</td><td>chennai</td></tr><tr><td>2</td><td>Smithaaaaaa</td><td>30</td><td>salem</td></tr><tr><td>7</td><td>bbbb</td><td>35</td><td>covai</td></tr><tr><td>8</td><td>cccc</td><td>40</td><td>trichy</td></tr><tr><td>5</td><td>Mikeeeeeeee</td><td>45</td><td>ooty</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "john cena",
         25,
         "chennai"
        ],
        [
         3,
         "Sarah",
         35,
         "covai"
        ],
        [
         4,
         "Mary",
         40,
         "trichy"
        ],
        [
         6,
         "aaaaa",
         25,
         "chennai"
        ],
        [
         2,
         "Smithaaaaaa",
         30,
         "salem"
        ],
        [
         7,
         "bbbb",
         35,
         "covai"
        ],
        [
         8,
         "cccc",
         40,
         "trichy"
        ],
        [
         5,
         "Mikeeeeeeee",
         45,
         "ooty"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "cust_id",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cust_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cust_age",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cust_city",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 114
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "cust_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cust_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cust_age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cust_city",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from delta.`/Volumes/delta/deltaschema/sink`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23201a06-a0e5-4da9-ad63-6136241a9027",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **TABLE UTILITY COMMANDS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9684e7de-15b8-45b0-ad21-b9f6133cadef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>id</td><td>int</td><td>null</td></tr><tr><td>name</td><td>string</td><td>null</td></tr><tr><td>age</td><td>int</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "id",
         "int",
         null
        ],
        [
         "name",
         "string",
         null
        ],
        [
         "age",
         "int",
         null
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "col_name",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "data_type",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comment",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 118
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "describe delta.deltaschema.deltatable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4d9201e-87fa-4b24-a710-8ffa7d759bac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c992158-2672-41f8-b110-5647eab29d66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>cust_id</td><td>bigint</td><td>null</td></tr><tr><td>cust_name</td><td>string</td><td>null</td></tr><tr><td>cust_age</td><td>bigint</td><td>null</td></tr><tr><td>cust_city</td><td>string</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "cust_id",
         "bigint",
         null
        ],
        [
         "cust_name",
         "string",
         null
        ],
        [
         "cust_age",
         "bigint",
         null
        ],
        [
         "cust_city",
         "string",
         null
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "col_name",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "data_type",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comment",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 119
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "describe delta.`/Volumes/delta/deltaschema/sink`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70ea32cc-109f-431c-84b1-35096bd4891d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>id</td><td>int</td><td>null</td></tr><tr><td>name</td><td>string</td><td>null</td></tr><tr><td>age</td><td>int</td><td>null</td></tr><tr><td></td><td></td><td></td></tr><tr><td># Delta Statistics Columns</td><td></td><td></td></tr><tr><td>Column Names</td><td>id, name, age</td><td></td></tr><tr><td>Column Selection Method</td><td>first-32</td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td># Detailed Table Information</td><td></td><td></td></tr><tr><td>Catalog</td><td>delta</td><td></td></tr><tr><td>Database</td><td>deltaschema</td><td></td></tr><tr><td>Table</td><td>deltatable</td><td></td></tr><tr><td>Created Time</td><td>Sat Jul 12 05:58:28 UTC 2025</td><td></td></tr><tr><td>Last Access</td><td>UNKNOWN</td><td></td></tr><tr><td>Created By</td><td>Spark </td><td></td></tr><tr><td>Statistics</td><td>2034 bytes, 8 rows</td><td></td></tr><tr><td>Type</td><td>MANAGED</td><td></td></tr><tr><td>Location</td><td></td><td></td></tr><tr><td>Provider</td><td>delta</td><td></td></tr><tr><td>Owner</td><td>dshkr2002@gmail.com</td><td></td></tr><tr><td>Is_managed_location</td><td>true</td><td></td></tr><tr><td>Predictive Optimization</td><td>ENABLE (inherited from METASTORE metastore_aws_us_east_2)</td><td></td></tr><tr><td>Table Properties</td><td>[delta.enableDeletionVectors=true,delta.feature.appendOnly=supported,delta.feature.deletionVectors=supported,delta.feature.invariants=supported,delta.minReaderVersion=3,delta.minWriterVersion=7]</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "id",
         "int",
         null
        ],
        [
         "name",
         "string",
         null
        ],
        [
         "age",
         "int",
         null
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Delta Statistics Columns",
         "",
         ""
        ],
        [
         "Column Names",
         "id, name, age",
         ""
        ],
        [
         "Column Selection Method",
         "first-32",
         ""
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Detailed Table Information",
         "",
         ""
        ],
        [
         "Catalog",
         "delta",
         ""
        ],
        [
         "Database",
         "deltaschema",
         ""
        ],
        [
         "Table",
         "deltatable",
         ""
        ],
        [
         "Created Time",
         "Sat Jul 12 05:58:28 UTC 2025",
         ""
        ],
        [
         "Last Access",
         "UNKNOWN",
         ""
        ],
        [
         "Created By",
         "Spark ",
         ""
        ],
        [
         "Statistics",
         "2034 bytes, 8 rows",
         ""
        ],
        [
         "Type",
         "MANAGED",
         ""
        ],
        [
         "Location",
         "",
         ""
        ],
        [
         "Provider",
         "delta",
         ""
        ],
        [
         "Owner",
         "dshkr2002@gmail.com",
         ""
        ],
        [
         "Is_managed_location",
         "true",
         ""
        ],
        [
         "Predictive Optimization",
         "ENABLE (inherited from METASTORE metastore_aws_us_east_2)",
         ""
        ],
        [
         "Table Properties",
         "[delta.enableDeletionVectors=true,delta.feature.appendOnly=supported,delta.feature.deletionVectors=supported,delta.feature.invariants=supported,delta.minReaderVersion=3,delta.minWriterVersion=7]",
         ""
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "col_name",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "data_type",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comment",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 120
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "describe extended delta.deltaschema.deltatable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a86e849b-ff2d-43dc-88f9-dfa93234983f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a48fecea-3d15-46a7-8f45-cdde8fdbc397",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>cust_id</td><td>bigint</td><td>null</td></tr><tr><td>cust_name</td><td>string</td><td>null</td></tr><tr><td>cust_age</td><td>bigint</td><td>null</td></tr><tr><td>cust_city</td><td>string</td><td>null</td></tr><tr><td></td><td></td><td></td></tr><tr><td># Delta Statistics Columns</td><td></td><td></td></tr><tr><td>Column Names</td><td>cust_id, cust_name, cust_age, cust_city</td><td></td></tr><tr><td>Column Selection Method</td><td>first-32</td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td># Detailed Table Information</td><td></td><td></td></tr><tr><td>Catalog</td><td>workspace</td><td></td></tr><tr><td>Database</td><td>delta</td><td></td></tr><tr><td>Table</td><td>/Volumes/delta/deltaschema/sink</td><td></td></tr><tr><td>Type</td><td>MANAGED</td><td></td></tr><tr><td>Location</td><td>/Volumes/delta/deltaschema/sink</td><td></td></tr><tr><td>Provider</td><td>delta</td><td></td></tr><tr><td>Table Properties</td><td>[delta.enableDeletionVectors=true,delta.feature.appendOnly=supported,delta.feature.deletionVectors=supported,delta.feature.invariants=supported,delta.minReaderVersion=3,delta.minWriterVersion=7]</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "cust_id",
         "bigint",
         null
        ],
        [
         "cust_name",
         "string",
         null
        ],
        [
         "cust_age",
         "bigint",
         null
        ],
        [
         "cust_city",
         "string",
         null
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Delta Statistics Columns",
         "",
         ""
        ],
        [
         "Column Names",
         "cust_id, cust_name, cust_age, cust_city",
         ""
        ],
        [
         "Column Selection Method",
         "first-32",
         ""
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Detailed Table Information",
         "",
         ""
        ],
        [
         "Catalog",
         "workspace",
         ""
        ],
        [
         "Database",
         "delta",
         ""
        ],
        [
         "Table",
         "/Volumes/delta/deltaschema/sink",
         ""
        ],
        [
         "Type",
         "MANAGED",
         ""
        ],
        [
         "Location",
         "/Volumes/delta/deltaschema/sink",
         ""
        ],
        [
         "Provider",
         "delta",
         ""
        ],
        [
         "Table Properties",
         "[delta.enableDeletionVectors=true,delta.feature.appendOnly=supported,delta.feature.deletionVectors=supported,delta.feature.invariants=supported,delta.minReaderVersion=3,delta.minWriterVersion=7]",
         ""
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "col_name",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "data_type",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comment",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 122
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "describe extended delta.`/Volumes/delta/deltaschema/sink`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c245bb14-151c-40d3-97fa-7be846b8941c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>2</td><td>2025-07-12T07:06:26.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>null</td><td>0712-055808-xwnwn6c7-v2n</td><td>1</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 4, numOutputBytes -> 1017)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr><tr><td>1</td><td>2025-07-12T06:00:51.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>null</td><td>0712-055808-xwnwn6c7-v2n</td><td>0</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 4, numOutputBytes -> 1017)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr><tr><td>0</td><td>2025-07-12T05:58:29.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>CREATE TABLE</td><td>Map(partitionBy -> [], clusterBy -> [], description -> null, isManaged -> true, properties -> {\"delta.enableDeletionVectors\":\"true\"}, statsOnLoad -> false)</td><td>null</td><td>null</td><td>0712-055808-xwnwn6c7-v2n</td><td>null</td><td>WriteSerializable</td><td>true</td><td>Map()</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2,
         "2025-07-12T07:06:26.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         null,
         "0712-055808-xwnwn6c7-v2n",
         1,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1017",
          "numOutputRows": "4"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ],
        [
         1,
         "2025-07-12T06:00:51.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         null,
         "0712-055808-xwnwn6c7-v2n",
         0,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1017",
          "numOutputRows": "4"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ],
        [
         0,
         "2025-07-12T05:58:29.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "CREATE TABLE",
         {
          "clusterBy": "[]",
          "description": null,
          "isManaged": "true",
          "partitionBy": "[]",
          "properties": "{\"delta.enableDeletionVectors\":\"true\"}",
          "statsOnLoad": "false"
         },
         null,
         null,
         "0712-055808-xwnwn6c7-v2n",
         null,
         "WriteSerializable",
         true,
         {},
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "version",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "timestamp",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "userId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "userName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operation",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operationParameters",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "job",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "jobId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobName",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobRunId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "runId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobOwnerId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "triggerType",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "notebook",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "notebookId",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "clusterId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "readVersion",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "isolationLevel",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "isBlindAppend",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "operationMetrics",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "userMetadata",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "engineInfo",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 124
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"jobId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobName\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobRunId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"runId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobOwnerId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"triggerType\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"notebookId\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "describe history delta.deltaschema.deltatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2fd2ad2-c4eb-4d55-a8cd-e002beb7b365",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>7</td><td>2025-07-12T07:22:20.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>OPTIMIZE</td><td>Map(predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0)</td><td>null</td><td>null</td><td>0712-055808-xwnwn6c7-v2n</td><td>6</td><td>SnapshotIsolation</td><td>false</td><td>Map(numRemovedFiles -> 6, numRemovedBytes -> 7768, p25FileSize -> 1512, numDeletionVectorsRemoved -> 1, minFileSize -> 1512, numAddedFiles -> 1, maxFileSize -> 1512, p75FileSize -> 1512, p50FileSize -> 1512, numAddedBytes -> 1512)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr><tr><td>6</td><td>2025-07-12T07:22:18.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>MERGE</td><td>Map(predicate -> [\"(cust_id#13431L = cust_id#13398L)\"], clusterBy -> [], matchedPredicates -> [{\"actionType\":\"update\"}], statsOnLoad -> false, notMatchedBySourcePredicates -> [], notMatchedPredicates -> [{\"actionType\":\"insert\"}])</td><td>null</td><td>null</td><td>0712-055808-xwnwn6c7-v2n</td><td>5</td><td>WriteSerializable</td><td>false</td><td>Map(numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 5, numTargetBytesAdded -> 6368, numTargetBytesRemoved -> 0, numTargetDeletionVectorsAdded -> 1, numTargetRowsMatchedUpdated -> 2, executionTimeMs -> 2890, materializeSourceTimeMs -> 154, numTargetRowsInserted -> 3, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 1091, numTargetRowsUpdated -> 2, numOutputRows -> 5, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 5, numTargetFilesRemoved -> 0, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 1558)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr><tr><td>5</td><td>2025-07-12T07:12:13.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>OPTIMIZE</td><td>Map(predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0)</td><td>null</td><td>null</td><td>0712-055808-xwnwn6c7-v2n</td><td>4</td><td>SnapshotIsolation</td><td>false</td><td>Map(numRemovedFiles -> 2, numRemovedBytes -> 2680, p25FileSize -> 1400, numDeletionVectorsRemoved -> 1, minFileSize -> 1400, numAddedFiles -> 1, maxFileSize -> 1400, p75FileSize -> 1400, p50FileSize -> 1400, numAddedBytes -> 1400)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr><tr><td>4</td><td>2025-07-12T07:12:11.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>UPDATE</td><td>Map(predicate -> [\"(cust_id#12571L = 1)\"])</td><td>null</td><td>null</td><td>0712-055808-xwnwn6c7-v2n</td><td>3</td><td>WriteSerializable</td><td>false</td><td>Map(numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 1, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 2831, numDeletionVectorsUpdated -> 0, scanTimeMs -> 1710, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1294, rewriteTimeMs -> 1102)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr><tr><td>3</td><td>2025-07-12T07:06:47.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>WRITE</td><td>Map(mode -> Overwrite, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>null</td><td>0712-055808-xwnwn6c7-v2n</td><td>2</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 1, numRemovedFiles -> 1, numRemovedBytes -> 1386, numOutputRows -> 5, numOutputBytes -> 1386)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr><tr><td>2</td><td>2025-07-12T07:02:25.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>WRITE</td><td>Map(mode -> Overwrite, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>null</td><td>0712-055808-xwnwn6c7-v2n</td><td>1</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 1, numRemovedFiles -> 2, numRemovedBytes -> 2421, numOutputRows -> 5, numOutputBytes -> 1386)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr><tr><td>1</td><td>2025-07-12T06:44:54.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>null</td><td>0712-055808-xwnwn6c7-v2n</td><td>0</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 1326)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr><tr><td>0</td><td>2025-07-12T06:25:02.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>null</td><td>0712-055808-xwnwn6c7-v2n</td><td>null</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 1095)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         7,
         "2025-07-12T07:22:20.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "OPTIMIZE",
         {
          "auto": "true",
          "batchId": "0",
          "clusterBy": "[]",
          "predicate": "[]",
          "zOrderBy": "[]"
         },
         null,
         null,
         "0712-055808-xwnwn6c7-v2n",
         6,
         "SnapshotIsolation",
         false,
         {
          "maxFileSize": "1512",
          "minFileSize": "1512",
          "numAddedBytes": "1512",
          "numAddedFiles": "1",
          "numDeletionVectorsRemoved": "1",
          "numRemovedBytes": "7768",
          "numRemovedFiles": "6",
          "p25FileSize": "1512",
          "p50FileSize": "1512",
          "p75FileSize": "1512"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ],
        [
         6,
         "2025-07-12T07:22:18.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "MERGE",
         {
          "clusterBy": "[]",
          "matchedPredicates": "[{\"actionType\":\"update\"}]",
          "notMatchedBySourcePredicates": "[]",
          "notMatchedPredicates": "[{\"actionType\":\"insert\"}]",
          "predicate": "[\"(cust_id#13431L = cust_id#13398L)\"]",
          "statsOnLoad": "false"
         },
         null,
         null,
         "0712-055808-xwnwn6c7-v2n",
         5,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "2890",
          "materializeSourceTimeMs": "154",
          "numOutputRows": "5",
          "numSourceRows": "5",
          "numTargetBytesAdded": "6368",
          "numTargetBytesRemoved": "0",
          "numTargetChangeFilesAdded": "0",
          "numTargetDeletionVectorsAdded": "1",
          "numTargetDeletionVectorsRemoved": "0",
          "numTargetDeletionVectorsUpdated": "0",
          "numTargetFilesAdded": "5",
          "numTargetFilesRemoved": "0",
          "numTargetRowsCopied": "0",
          "numTargetRowsDeleted": "0",
          "numTargetRowsInserted": "3",
          "numTargetRowsMatchedDeleted": "0",
          "numTargetRowsMatchedUpdated": "2",
          "numTargetRowsNotMatchedBySourceDeleted": "0",
          "numTargetRowsNotMatchedBySourceUpdated": "0",
          "numTargetRowsUpdated": "2",
          "rewriteTimeMs": "1558",
          "scanTimeMs": "1091"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ],
        [
         5,
         "2025-07-12T07:12:13.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "OPTIMIZE",
         {
          "auto": "true",
          "batchId": "0",
          "clusterBy": "[]",
          "predicate": "[]",
          "zOrderBy": "[]"
         },
         null,
         null,
         "0712-055808-xwnwn6c7-v2n",
         4,
         "SnapshotIsolation",
         false,
         {
          "maxFileSize": "1400",
          "minFileSize": "1400",
          "numAddedBytes": "1400",
          "numAddedFiles": "1",
          "numDeletionVectorsRemoved": "1",
          "numRemovedBytes": "2680",
          "numRemovedFiles": "2",
          "p25FileSize": "1400",
          "p50FileSize": "1400",
          "p75FileSize": "1400"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ],
        [
         4,
         "2025-07-12T07:12:11.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "UPDATE",
         {
          "predicate": "[\"(cust_id#12571L = 1)\"]"
         },
         null,
         null,
         "0712-055808-xwnwn6c7-v2n",
         3,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "2831",
          "numAddedBytes": "1294",
          "numAddedChangeFiles": "0",
          "numAddedFiles": "1",
          "numCopiedRows": "0",
          "numDeletionVectorsAdded": "1",
          "numDeletionVectorsRemoved": "0",
          "numDeletionVectorsUpdated": "0",
          "numRemovedBytes": "0",
          "numRemovedFiles": "0",
          "numUpdatedRows": "1",
          "rewriteTimeMs": "1102",
          "scanTimeMs": "1710"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ],
        [
         3,
         "2025-07-12T07:06:47.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "WRITE",
         {
          "mode": "Overwrite",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         null,
         "0712-055808-xwnwn6c7-v2n",
         2,
         "WriteSerializable",
         false,
         {
          "numFiles": "1",
          "numOutputBytes": "1386",
          "numOutputRows": "5",
          "numRemovedBytes": "1386",
          "numRemovedFiles": "1"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ],
        [
         2,
         "2025-07-12T07:02:25.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "WRITE",
         {
          "mode": "Overwrite",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         null,
         "0712-055808-xwnwn6c7-v2n",
         1,
         "WriteSerializable",
         false,
         {
          "numFiles": "1",
          "numOutputBytes": "1386",
          "numOutputRows": "5",
          "numRemovedBytes": "2421",
          "numRemovedFiles": "2"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ],
        [
         1,
         "2025-07-12T06:44:54.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         null,
         "0712-055808-xwnwn6c7-v2n",
         0,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1326",
          "numOutputRows": "5"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ],
        [
         0,
         "2025-07-12T06:25:02.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         null,
         "0712-055808-xwnwn6c7-v2n",
         null,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1095",
          "numOutputRows": "5"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "version",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "timestamp",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "userId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "userName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operation",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operationParameters",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "job",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "jobId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobName",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobRunId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "runId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobOwnerId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "triggerType",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "notebook",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "notebookId",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "clusterId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "readVersion",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "isolationLevel",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "isBlindAppend",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "operationMetrics",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "userMetadata",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "engineInfo",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 125
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"jobId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobName\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobRunId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"runId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobOwnerId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"triggerType\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"notebookId\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "describe history delta.`/Volumes/delta/deltaschema/sink`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a173f3b-52c4-457d-84ad-c91a5b7aab42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>cust_id</th><th>cust_name</th><th>cust_age</th><th>cust_city</th></tr></thead><tbody><tr><td>2</td><td>Smith</td><td>30</td><td>salem</td></tr><tr><td>3</td><td>Sarah</td><td>35</td><td>covai</td></tr><tr><td>4</td><td>Mary</td><td>40</td><td>trichy</td></tr><tr><td>5</td><td>Mike</td><td>45</td><td>ooty</td></tr><tr><td>1</td><td>john cena</td><td>25</td><td>chennai</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2,
         "Smith",
         30,
         "salem"
        ],
        [
         3,
         "Sarah",
         35,
         "covai"
        ],
        [
         4,
         "Mary",
         40,
         "trichy"
        ],
        [
         5,
         "Mike",
         45,
         "ooty"
        ],
        [
         1,
         "john cena",
         25,
         "chennai"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "cust_id",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cust_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cust_age",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cust_city",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 128
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "cust_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cust_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cust_age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cust_city",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from delta.`/Volumes/delta/deltaschema/sink`\n",
    "version as of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c01ea36-b475-4cd3-ac09-ae71f05a9484",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>cust_id</th><th>cust_name</th><th>cust_age</th><th>cust_city</th></tr></thead><tbody><tr><td>1</td><td>john cena</td><td>25</td><td>chennai</td></tr><tr><td>3</td><td>Sarah</td><td>35</td><td>covai</td></tr><tr><td>4</td><td>Mary</td><td>40</td><td>trichy</td></tr><tr><td>6</td><td>aaaaa</td><td>25</td><td>chennai</td></tr><tr><td>2</td><td>Smithaaaaaa</td><td>30</td><td>salem</td></tr><tr><td>7</td><td>bbbb</td><td>35</td><td>covai</td></tr><tr><td>8</td><td>cccc</td><td>40</td><td>trichy</td></tr><tr><td>5</td><td>Mikeeeeeeee</td><td>45</td><td>ooty</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "john cena",
         25,
         "chennai"
        ],
        [
         3,
         "Sarah",
         35,
         "covai"
        ],
        [
         4,
         "Mary",
         40,
         "trichy"
        ],
        [
         6,
         "aaaaa",
         25,
         "chennai"
        ],
        [
         2,
         "Smithaaaaaa",
         30,
         "salem"
        ],
        [
         7,
         "bbbb",
         35,
         "covai"
        ],
        [
         8,
         "cccc",
         40,
         "trichy"
        ],
        [
         5,
         "Mikeeeeeeee",
         45,
         "ooty"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "cust_id",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cust_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cust_age",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cust_city",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 129
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "cust_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cust_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cust_age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cust_city",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from delta.`/Volumes/delta/deltaschema/sink`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52547e23-dcf0-47ee-994a-4c2710796814",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>table_size_after_restore</th><th>num_of_files_after_restore</th><th>num_removed_files</th><th>num_restored_files</th><th>removed_files_size</th><th>restored_files_size</th></tr></thead><tbody><tr><td>2680</td><td>2</td><td>1</td><td>2</td><td>1512</td><td>2680</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2680,
         2,
         1,
         2,
         1512,
         2680
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "table_size_after_restore",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_of_files_after_restore",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_removed_files",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_restored_files",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "removed_files_size",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "restored_files_size",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 131
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "table_size_after_restore",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_of_files_after_restore",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_removed_files",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_restored_files",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "removed_files_size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "restored_files_size",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "restore delta.`/Volumes/delta/deltaschema/sink`\n",
    "version as of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a3cc4a2-df6e-4ab4-8f2e-9b6f100017fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>cust_id</th><th>cust_name</th><th>cust_age</th><th>cust_city</th></tr></thead><tbody><tr><td>2</td><td>Smith</td><td>30</td><td>salem</td></tr><tr><td>3</td><td>Sarah</td><td>35</td><td>covai</td></tr><tr><td>4</td><td>Mary</td><td>40</td><td>trichy</td></tr><tr><td>5</td><td>Mike</td><td>45</td><td>ooty</td></tr><tr><td>1</td><td>john cena</td><td>25</td><td>chennai</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2,
         "Smith",
         30,
         "salem"
        ],
        [
         3,
         "Sarah",
         35,
         "covai"
        ],
        [
         4,
         "Mary",
         40,
         "trichy"
        ],
        [
         5,
         "Mike",
         45,
         "ooty"
        ],
        [
         1,
         "john cena",
         25,
         "chennai"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "cust_id",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cust_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "cust_age",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "cust_city",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 132
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "cust_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cust_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cust_age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cust_city",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from delta.`/Volumes/delta/deltaschema/sink`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53b8e22f-7032-4303-981a-781521c15442",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>key</th><th>value</th></tr></thead><tbody><tr><td>delta.enableDeletionVectors</td><td>true</td></tr><tr><td>delta.feature.appendOnly</td><td>supported</td></tr><tr><td>delta.feature.deletionVectors</td><td>supported</td></tr><tr><td>delta.feature.invariants</td><td>supported</td></tr><tr><td>delta.minReaderVersion</td><td>3</td></tr><tr><td>delta.minWriterVersion</td><td>7</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "delta.enableDeletionVectors",
         "true"
        ],
        [
         "delta.feature.appendOnly",
         "supported"
        ],
        [
         "delta.feature.deletionVectors",
         "supported"
        ],
        [
         "delta.feature.invariants",
         "supported"
        ],
        [
         "delta.minReaderVersion",
         "3"
        ],
        [
         "delta.minWriterVersion",
         "7"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "key",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "value",
            "nullable": false,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 133
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "key",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "value",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "show tblproperties delta.deltaschema.deltatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95a22bbf-0596-4d2c-99ac-f23115bab57d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>source_table_size</th><th>source_num_of_files</th><th>num_of_synced_transactions</th><th>num_removed_files</th><th>num_copied_files</th><th>removed_files_size</th><th>copied_files_size</th></tr></thead><tbody><tr><td>2034</td><td>2</td><td>null</td><td>0</td><td>2</td><td>0</td><td>2034</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2034,
         2,
         null,
         0,
         2,
         0,
         2034
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "source_table_size",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "source_num_of_files",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_of_synced_transactions",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_removed_files",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_copied_files",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "removed_files_size",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "copied_files_size",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 135
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "source_table_size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "source_num_of_files",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_of_synced_transactions",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_removed_files",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_copied_files",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "removed_files_size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "copied_files_size",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "create table delta.deltaschema.deltatable2\n",
    "clone delta.deltaschema.deltatable\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eee019ff-6dea-47c9-9e5f-529f8b7da5ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>city</th></tr></thead><tbody><tr><td>1</td><td>aaa</td><td>chennai</td></tr><tr><td>2</td><td>bbb</td><td>salem</td></tr><tr><td>3</td><td>ccc</td><td>covai</td></tr><tr><td>4</td><td>ddd</td><td>trichy</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "aaa",
         "chennai"
        ],
        [
         2,
         "bbb",
         "salem"
        ],
        [
         3,
         "ccc",
         "covai"
        ],
        [
         4,
         "ddd",
         "trichy"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "city",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data4 = [(1,\"aaa\",\"chennai\"),(2,\"bbb\",\"salem\"),(3,\"ccc\",\"covai\"),(4,\"ddd\",\"trichy\")]\n",
    "\n",
    "\n",
    "schema4 = ['id','name','city']\n",
    "\n",
    "df4 = spark.createDataFrame(data4,schema4)\n",
    "\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc114ff3-f80c-47ad-93ae-1dbb2d712c06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df4.write.format(\"delta\")\\\n",
    "    .mode(\"append\")\\\n",
    "    .save(\"/Volumes/delta/deltaschema/optimization/optimize\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92d73dfa-eda5-46a1-b569-ae55e0261947",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>0</td><td>2025-07-12T13:49:06.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>null</td><td>0712-134530-qhpwm4jy-v2n</td><td>null</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 4, numOutputBytes -> 1076)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         "2025-07-12T13:49:06.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         null,
         "0712-134530-qhpwm4jy-v2n",
         null,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1076",
          "numOutputRows": "4"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "version",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "timestamp",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "userId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "userName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operation",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operationParameters",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "job",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "jobId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobName",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobRunId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "runId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobOwnerId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "triggerType",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "notebook",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "notebookId",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "clusterId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "readVersion",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "isolationLevel",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "isBlindAppend",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "operationMetrics",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "userMetadata",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "engineInfo",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 7
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"jobId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobName\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobRunId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"runId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobOwnerId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"triggerType\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"notebookId\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "describe history delta.`/Volumes/delta/deltaschema/optimization/optimize/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d67b6dc-4be2-4caa-b60c-19948c97857e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th></tr></thead><tbody><tr><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "num_affected_rows",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 8
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "update delta.`/Volumes/delta/deltaschema/optimization/optimize/`\n",
    "set name = 'updated'\n",
    "where id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af19b30f-668c-4995-b9e5-20faed38d97d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>2</td><td>2025-07-12T13:51:30.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>OPTIMIZE</td><td>Map(predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0)</td><td>null</td><td>null</td><td>0712-134530-qhpwm4jy-v2n</td><td>1</td><td>SnapshotIsolation</td><td>false</td><td>Map(numRemovedFiles -> 2, numRemovedBytes -> 2106, p25FileSize -> 1089, numDeletionVectorsRemoved -> 1, minFileSize -> 1089, numAddedFiles -> 1, maxFileSize -> 1089, p75FileSize -> 1089, p50FileSize -> 1089, numAddedBytes -> 1089)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr><tr><td>1</td><td>2025-07-12T13:51:28.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>UPDATE</td><td>Map(predicate -> [\"(id#10828L = 1)\"])</td><td>null</td><td>null</td><td>0712-134530-qhpwm4jy-v2n</td><td>0</td><td>WriteSerializable</td><td>false</td><td>Map(numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 1, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 3493, numDeletionVectorsUpdated -> 0, scanTimeMs -> 2106, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1030, rewriteTimeMs -> 1352)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr><tr><td>0</td><td>2025-07-12T13:49:06.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>null</td><td>0712-134530-qhpwm4jy-v2n</td><td>null</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 4, numOutputBytes -> 1076)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2,
         "2025-07-12T13:51:30.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "OPTIMIZE",
         {
          "auto": "true",
          "batchId": "0",
          "clusterBy": "[]",
          "predicate": "[]",
          "zOrderBy": "[]"
         },
         null,
         null,
         "0712-134530-qhpwm4jy-v2n",
         1,
         "SnapshotIsolation",
         false,
         {
          "maxFileSize": "1089",
          "minFileSize": "1089",
          "numAddedBytes": "1089",
          "numAddedFiles": "1",
          "numDeletionVectorsRemoved": "1",
          "numRemovedBytes": "2106",
          "numRemovedFiles": "2",
          "p25FileSize": "1089",
          "p50FileSize": "1089",
          "p75FileSize": "1089"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ],
        [
         1,
         "2025-07-12T13:51:28.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "UPDATE",
         {
          "predicate": "[\"(id#10828L = 1)\"]"
         },
         null,
         null,
         "0712-134530-qhpwm4jy-v2n",
         0,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "3493",
          "numAddedBytes": "1030",
          "numAddedChangeFiles": "0",
          "numAddedFiles": "1",
          "numCopiedRows": "0",
          "numDeletionVectorsAdded": "1",
          "numDeletionVectorsRemoved": "0",
          "numDeletionVectorsUpdated": "0",
          "numRemovedBytes": "0",
          "numRemovedFiles": "0",
          "numUpdatedRows": "1",
          "rewriteTimeMs": "1352",
          "scanTimeMs": "2106"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ],
        [
         0,
         "2025-07-12T13:49:06.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         null,
         "0712-134530-qhpwm4jy-v2n",
         null,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1076",
          "numOutputRows": "4"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "version",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "timestamp",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "userId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "userName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operation",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operationParameters",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "job",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "jobId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobName",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobRunId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "runId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobOwnerId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "triggerType",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "notebook",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "notebookId",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "clusterId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "readVersion",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "isolationLevel",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "isBlindAppend",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "operationMetrics",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "userMetadata",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "engineInfo",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 10
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"jobId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobName\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobRunId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"runId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobOwnerId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"triggerType\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"notebookId\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "describe history delta.`/Volumes/delta/deltaschema/optimization/optimize/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00cf50e9-561d-4470-853e-48bd4d6fadca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "624e6160-8899-49ae-8fae-81ab1a48068e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>metrics</th></tr></thead><tbody><tr><td>dbfs:/Volumes/delta/deltaschema/optimization/optimize</td><td>List(0, 0, List(null, null, 0.0, 0, 0), List(null, null, 0.0, 0, 0), 0, null, null, 0, 0, 1, 1, true, 0, 0, 1752328384737, 1752328385189, 8, 0, null, List(0, 0), null, 3, 3, 0, 0, null)</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/Volumes/delta/deltaschema/optimization/optimize",
         [
          0,
          0,
          [
           null,
           null,
           0.0,
           0,
           0
          ],
          [
           null,
           null,
           0.0,
           0,
           0
          ],
          0,
          null,
          null,
          0,
          0,
          1,
          1,
          true,
          0,
          0,
          1752328384737,
          1752328385189,
          8,
          0,
          null,
          [
           0,
           0
          ],
          null,
          3,
          3,
          0,
          0,
          null
         ]
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "path",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "metrics",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "numFilesAdded",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "numFilesRemoved",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "filesAdded",
               "nullable": true,
               "type": {
                "fields": [
                 {
                  "metadata": {},
                  "name": "min",
                  "nullable": true,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "max",
                  "nullable": true,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "avg",
                  "nullable": false,
                  "type": "double"
                 },
                 {
                  "metadata": {},
                  "name": "totalFiles",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "totalSize",
                  "nullable": false,
                  "type": "long"
                 }
                ],
                "type": "struct"
               }
              },
              {
               "metadata": {},
               "name": "filesRemoved",
               "nullable": true,
               "type": {
                "fields": [
                 {
                  "metadata": {},
                  "name": "min",
                  "nullable": true,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "max",
                  "nullable": true,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "avg",
                  "nullable": false,
                  "type": "double"
                 },
                 {
                  "metadata": {},
                  "name": "totalFiles",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "totalSize",
                  "nullable": false,
                  "type": "long"
                 }
                ],
                "type": "struct"
               }
              },
              {
               "metadata": {},
               "name": "partitionsOptimized",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "zOrderStats",
               "nullable": true,
               "type": {
                "fields": [
                 {
                  "metadata": {},
                  "name": "strategyName",
                  "nullable": true,
                  "type": "string"
                 },
                 {
                  "metadata": {},
                  "name": "inputCubeFiles",
                  "nullable": true,
                  "type": {
                   "fields": [
                    {
                     "metadata": {},
                     "name": "num",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "size",
                     "nullable": false,
                     "type": "long"
                    }
                   ],
                   "type": "struct"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "inputOtherFiles",
                  "nullable": true,
                  "type": {
                   "fields": [
                    {
                     "metadata": {},
                     "name": "num",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "size",
                     "nullable": false,
                     "type": "long"
                    }
                   ],
                   "type": "struct"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "inputNumCubes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "mergedFiles",
                  "nullable": true,
                  "type": {
                   "fields": [
                    {
                     "metadata": {},
                     "name": "num",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "size",
                     "nullable": false,
                     "type": "long"
                    }
                   ],
                   "type": "struct"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "numOutputCubes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "mergedNumCubes",
                  "nullable": true,
                  "type": "long"
                 }
                ],
                "type": "struct"
               }
              },
              {
               "metadata": {},
               "name": "clusteringStats",
               "nullable": true,
               "type": {
                "fields": [
                 {
                  "metadata": {},
                  "name": "inputZCubeFiles",
                  "nullable": true,
                  "type": {
                   "fields": [
                    {
                     "metadata": {},
                     "name": "numFiles",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "size",
                     "nullable": false,
                     "type": "long"
                    }
                   ],
                   "type": "struct"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "inputOtherFiles",
                  "nullable": true,
                  "type": {
                   "fields": [
                    {
                     "metadata": {},
                     "name": "numFiles",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "size",
                     "nullable": false,
                     "type": "long"
                    }
                   ],
                   "type": "struct"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "inputNumZCubes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "mergedFiles",
                  "nullable": true,
                  "type": {
                   "fields": [
                    {
                     "metadata": {},
                     "name": "numFiles",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "size",
                     "nullable": false,
                     "type": "long"
                    }
                   ],
                   "type": "struct"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "numOutputZCubes",
                  "nullable": false,
                  "type": "long"
                 }
                ],
                "type": "struct"
               }
              },
              {
               "metadata": {},
               "name": "numBins",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "numBatches",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "totalConsideredFiles",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "totalFilesSkipped",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "preserveInsertionOrder",
               "nullable": false,
               "type": "boolean"
              },
              {
               "metadata": {},
               "name": "numFilesSkippedToReduceWriteAmplification",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "numBytesSkippedToReduceWriteAmplification",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "startTimeMs",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "endTimeMs",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "totalClusterParallelism",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "totalScheduledTasks",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "autoCompactParallelismStats",
               "nullable": true,
               "type": {
                "fields": [
                 {
                  "metadata": {},
                  "name": "maxClusterActiveParallelism",
                  "nullable": true,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "minClusterActiveParallelism",
                  "nullable": true,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "maxSessionActiveParallelism",
                  "nullable": true,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "minSessionActiveParallelism",
                  "nullable": true,
                  "type": "long"
                 }
                ],
                "type": "struct"
               }
              },
              {
               "metadata": {},
               "name": "deletionVectorStats",
               "nullable": true,
               "type": {
                "fields": [
                 {
                  "metadata": {},
                  "name": "numDeletionVectorsRemoved",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numDeletionVectorRowsRemoved",
                  "nullable": false,
                  "type": "long"
                 }
                ],
                "type": "struct"
               }
              },
              {
               "metadata": {},
               "name": "recompressionCodec",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "numTableColumns",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "numTableColumnsWithStats",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "totalTaskExecutionTimeMs",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "skippedArchivedFiles",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "clusteringMetrics",
               "nullable": true,
               "type": {
                "fields": [
                 {
                  "metadata": {},
                  "name": "sizeOfTableInBytesBeforeLazyClustering",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "isNewMetadataCreated",
                  "nullable": false,
                  "type": "boolean"
                 },
                 {
                  "metadata": {},
                  "name": "isPOTriggered",
                  "nullable": false,
                  "type": "boolean"
                 },
                 {
                  "metadata": {},
                  "name": "isFull",
                  "nullable": false,
                  "type": "boolean"
                 },
                 {
                  "metadata": {},
                  "name": "approxClusteringQuality",
                  "nullable": true,
                  "type": "double"
                 },
                 {
                  "metadata": {},
                  "name": "approxClusteringQualityPerColumn",
                  "nullable": true,
                  "type": {
                   "containsNull": false,
                   "elementType": "double",
                   "type": "array"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "approxClusteringCoverage",
                  "nullable": true,
                  "type": "double"
                 },
                 {
                  "metadata": {},
                  "name": "numFilesSkippedWithoutStats",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numFilesClassifiedToIntermediateNodes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "sizeOfFilesClassifiedToIntermediateNodesInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "logicalSizeOfFilesClassifiedToIntermediateNodesInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numFilesClassifiedToLeafNodes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "sizeOfFilesClassifiedToLeafNodesInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "logicalSizeOfFilesClassifiedToLeafNodesInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numThreadsForClassifier",
                  "nullable": true,
                  "type": "integer"
                 },
                 {
                  "metadata": {},
                  "name": "clusterThresholdStrategy",
                  "nullable": true,
                  "type": "string"
                 },
                 {
                  "metadata": {},
                  "name": "minFileSize",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "maxFileSize",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "nodeMinNumFilesToCompact",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numIdealFiles",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numIdealFilesWithTrimmedStringMaxValue",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numAddedFilesWithSameMinMaxOnClusteringColumns",
                  "nullable": true,
                  "type": {
                   "containsNull": false,
                   "elementType": "long",
                   "type": "array"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "numClusteringTasksPlanned",
                  "nullable": false,
                  "type": "integer"
                 },
                 {
                  "metadata": {},
                  "name": "numCompactionTasksPlanned",
                  "nullable": false,
                  "type": "integer"
                 },
                 {
                  "metadata": {},
                  "name": "numOptimizeBatchesPlanned",
                  "nullable": false,
                  "type": "integer"
                 },
                 {
                  "metadata": {},
                  "name": "numLeafNodesExpanded",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numLeafNodesClustered",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numGetFilesForNodeCalls",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numSamplingJobs",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numLeafNodesCompacted",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numIntermediateNodesCompacted",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "totalSizeOfDataToCompactInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "totalLogicalSizeOfDataToCompactInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numIntermediateNodesClustered",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numFilesSkippedAfterExpansion",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "totalSizeOfFilesSkippedAfterExpansionInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "totalLogicalSizeOfFilesSkippedAfterExpansionInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "totalSizeOfDataToRewriteInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "totalLogicalSizeOfDataToRewriteInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "timeMetrics",
                  "nullable": true,
                  "type": {
                   "fields": [
                    {
                     "metadata": {},
                     "name": "classifierTimeMs",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "optimizerTimeMs",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "metadataLoadTimeMs",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "totalGetFilesForNodeCallsTimeMs",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "totalSamplingTimeMs",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "metadataCreationTimeMs",
                     "nullable": false,
                     "type": "long"
                    }
                   ],
                   "type": "struct"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "maxOptimizeBatchesInParallel",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "currentIteration",
                  "nullable": false,
                  "type": "integer"
                 },
                 {
                  "metadata": {},
                  "name": "maxIterations",
                  "nullable": false,
                  "type": "integer"
                 },
                 {
                  "metadata": {},
                  "name": "clusteringStrategy",
                  "nullable": true,
                  "type": "string"
                 }
                ],
                "type": "struct"
               }
              }
             ],
             "type": "struct"
            }
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 12
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "metrics",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"numFilesAdded\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numFilesRemoved\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"filesAdded\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"min\",\"nullable\":true,\"type\":\"long\"},{\"metadata\":{},\"name\":\"max\",\"nullable\":true,\"type\":\"long\"},{\"metadata\":{},\"name\":\"avg\",\"nullable\":false,\"type\":\"double\"},{\"metadata\":{},\"name\":\"totalFiles\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalSize\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"filesRemoved\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"min\",\"nullable\":true,\"type\":\"long\"},{\"metadata\":{},\"name\":\"max\",\"nullable\":true,\"type\":\"long\"},{\"metadata\":{},\"name\":\"avg\",\"nullable\":false,\"type\":\"double\"},{\"metadata\":{},\"name\":\"totalFiles\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalSize\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"partitionsOptimized\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"zOrderStats\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"strategyName\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"inputCubeFiles\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"num\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"size\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"inputOtherFiles\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"num\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"size\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"inputNumCubes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"mergedFiles\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"num\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"size\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"numOutputCubes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"mergedNumCubes\",\"nullable\":true,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"clusteringStats\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"inputZCubeFiles\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"numFiles\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"size\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"inputOtherFiles\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"numFiles\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"size\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"inputNumZCubes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"mergedFiles\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"numFiles\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"size\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"numOutputZCubes\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"numBins\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numBatches\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalConsideredFiles\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalFilesSkipped\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"preserveInsertionOrder\",\"nullable\":false,\"type\":\"boolean\"},{\"metadata\":{},\"name\":\"numFilesSkippedToReduceWriteAmplification\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numBytesSkippedToReduceWriteAmplification\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"startTimeMs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"endTimeMs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalClusterParallelism\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalScheduledTasks\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"autoCompactParallelismStats\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"maxClusterActiveParallelism\",\"nullable\":true,\"type\":\"long\"},{\"metadata\":{},\"name\":\"minClusterActiveParallelism\",\"nullable\":true,\"type\":\"long\"},{\"metadata\":{},\"name\":\"maxSessionActiveParallelism\",\"nullable\":true,\"type\":\"long\"},{\"metadata\":{},\"name\":\"minSessionActiveParallelism\",\"nullable\":true,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"deletionVectorStats\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"numDeletionVectorsRemoved\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numDeletionVectorRowsRemoved\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"recompressionCodec\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"numTableColumns\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numTableColumnsWithStats\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalTaskExecutionTimeMs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"skippedArchivedFiles\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"clusteringMetrics\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"sizeOfTableInBytesBeforeLazyClustering\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"isNewMetadataCreated\",\"nullable\":false,\"type\":\"boolean\"},{\"metadata\":{},\"name\":\"isPOTriggered\",\"nullable\":false,\"type\":\"boolean\"},{\"metadata\":{},\"name\":\"isFull\",\"nullable\":false,\"type\":\"boolean\"},{\"metadata\":{},\"name\":\"approxClusteringQuality\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"approxClusteringQualityPerColumn\",\"nullable\":true,\"type\":{\"containsNull\":false,\"elementType\":\"double\",\"type\":\"array\"}},{\"metadata\":{},\"name\":\"approxClusteringCoverage\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"numFilesSkippedWithoutStats\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numFilesClassifiedToIntermediateNodes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"sizeOfFilesClassifiedToIntermediateNodesInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"logicalSizeOfFilesClassifiedToIntermediateNodesInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numFilesClassifiedToLeafNodes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"sizeOfFilesClassifiedToLeafNodesInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"logicalSizeOfFilesClassifiedToLeafNodesInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numThreadsForClassifier\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"clusterThresholdStrategy\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"minFileSize\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"maxFileSize\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"nodeMinNumFilesToCompact\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numIdealFiles\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numIdealFilesWithTrimmedStringMaxValue\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numAddedFilesWithSameMinMaxOnClusteringColumns\",\"nullable\":true,\"type\":{\"containsNull\":false,\"elementType\":\"long\",\"type\":\"array\"}},{\"metadata\":{},\"name\":\"numClusteringTasksPlanned\",\"nullable\":false,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"numCompactionTasksPlanned\",\"nullable\":false,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"numOptimizeBatchesPlanned\",\"nullable\":false,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"numLeafNodesExpanded\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numLeafNodesClustered\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numGetFilesForNodeCalls\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numSamplingJobs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numLeafNodesCompacted\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numIntermediateNodesCompacted\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalSizeOfDataToCompactInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalLogicalSizeOfDataToCompactInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numIntermediateNodesClustered\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numFilesSkippedAfterExpansion\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalSizeOfFilesSkippedAfterExpansionInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalLogicalSizeOfFilesSkippedAfterExpansionInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalSizeOfDataToRewriteInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalLogicalSizeOfDataToRewriteInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"timeMetrics\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"classifierTimeMs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"optimizerTimeMs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"metadataLoadTimeMs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalGetFilesForNodeCallsTimeMs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalSamplingTimeMs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"metadataCreationTimeMs\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"maxOptimizeBatchesInParallel\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"currentIteration\",\"nullable\":false,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"maxIterations\",\"nullable\":false,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"clusteringStrategy\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}}],\"type\":\"struct\"}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "optimize delta.`/Volumes/delta/deltaschema/optimization/optimize/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08a874fb-e469-4d14-9610-69424ba1f59e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>2</td><td>2025-07-12T13:51:30.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>OPTIMIZE</td><td>Map(predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0)</td><td>null</td><td>null</td><td>0712-134530-qhpwm4jy-v2n</td><td>1</td><td>SnapshotIsolation</td><td>false</td><td>Map(numRemovedFiles -> 2, numRemovedBytes -> 2106, p25FileSize -> 1089, numDeletionVectorsRemoved -> 1, minFileSize -> 1089, numAddedFiles -> 1, maxFileSize -> 1089, p75FileSize -> 1089, p50FileSize -> 1089, numAddedBytes -> 1089)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr><tr><td>1</td><td>2025-07-12T13:51:28.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>UPDATE</td><td>Map(predicate -> [\"(id#10828L = 1)\"])</td><td>null</td><td>null</td><td>0712-134530-qhpwm4jy-v2n</td><td>0</td><td>WriteSerializable</td><td>false</td><td>Map(numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 1, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 3493, numDeletionVectorsUpdated -> 0, scanTimeMs -> 2106, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1030, rewriteTimeMs -> 1352)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr><tr><td>0</td><td>2025-07-12T13:49:06.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>null</td><td>0712-134530-qhpwm4jy-v2n</td><td>null</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 4, numOutputBytes -> 1076)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2,
         "2025-07-12T13:51:30.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "OPTIMIZE",
         {
          "auto": "true",
          "batchId": "0",
          "clusterBy": "[]",
          "predicate": "[]",
          "zOrderBy": "[]"
         },
         null,
         null,
         "0712-134530-qhpwm4jy-v2n",
         1,
         "SnapshotIsolation",
         false,
         {
          "maxFileSize": "1089",
          "minFileSize": "1089",
          "numAddedBytes": "1089",
          "numAddedFiles": "1",
          "numDeletionVectorsRemoved": "1",
          "numRemovedBytes": "2106",
          "numRemovedFiles": "2",
          "p25FileSize": "1089",
          "p50FileSize": "1089",
          "p75FileSize": "1089"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ],
        [
         1,
         "2025-07-12T13:51:28.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "UPDATE",
         {
          "predicate": "[\"(id#10828L = 1)\"]"
         },
         null,
         null,
         "0712-134530-qhpwm4jy-v2n",
         0,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "3493",
          "numAddedBytes": "1030",
          "numAddedChangeFiles": "0",
          "numAddedFiles": "1",
          "numCopiedRows": "0",
          "numDeletionVectorsAdded": "1",
          "numDeletionVectorsRemoved": "0",
          "numDeletionVectorsUpdated": "0",
          "numRemovedBytes": "0",
          "numRemovedFiles": "0",
          "numUpdatedRows": "1",
          "rewriteTimeMs": "1352",
          "scanTimeMs": "2106"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ],
        [
         0,
         "2025-07-12T13:49:06.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         null,
         "0712-134530-qhpwm4jy-v2n",
         null,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1076",
          "numOutputRows": "4"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "version",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "timestamp",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "userId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "userName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operation",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operationParameters",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "job",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "jobId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobName",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobRunId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "runId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobOwnerId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "triggerType",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "notebook",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "notebookId",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "clusterId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "readVersion",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "isolationLevel",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "isBlindAppend",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "operationMetrics",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "userMetadata",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "engineInfo",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 16
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"jobId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobName\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobRunId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"runId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobOwnerId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"triggerType\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"notebookId\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "describe history delta.`/Volumes/delta/deltaschema/optimization/optimize/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bf45629-b211-4c9f-823a-91be7f73e246",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## zorder by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f8d6142-4cb9-4f9c-92e8-4e985c1ef56b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>metrics</th></tr></thead><tbody><tr><td>dbfs:/Volumes/delta/deltaschema/optimization/optimize</td><td>List(0, 0, List(null, null, 0.0, 0, 0), List(null, null, 0.0, 0, 0), 0, List(minCubeSize(107374182400), List(0, 0), List(1, 1089), 0, List(0, 0), 0, null), null, 0, 0, 1, 1, false, 0, 0, 1752328511178, 1752328511622, 8, 0, null, List(0, 0), null, 3, 3, 0, 0, null)</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/Volumes/delta/deltaschema/optimization/optimize",
         [
          0,
          0,
          [
           null,
           null,
           0.0,
           0,
           0
          ],
          [
           null,
           null,
           0.0,
           0,
           0
          ],
          0,
          [
           "minCubeSize(107374182400)",
           [
            0,
            0
           ],
           [
            1,
            1089
           ],
           0,
           [
            0,
            0
           ],
           0,
           null
          ],
          null,
          0,
          0,
          1,
          1,
          false,
          0,
          0,
          1752328511178,
          1752328511622,
          8,
          0,
          null,
          [
           0,
           0
          ],
          null,
          3,
          3,
          0,
          0,
          null
         ]
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "path",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "metrics",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "numFilesAdded",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "numFilesRemoved",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "filesAdded",
               "nullable": true,
               "type": {
                "fields": [
                 {
                  "metadata": {},
                  "name": "min",
                  "nullable": true,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "max",
                  "nullable": true,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "avg",
                  "nullable": false,
                  "type": "double"
                 },
                 {
                  "metadata": {},
                  "name": "totalFiles",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "totalSize",
                  "nullable": false,
                  "type": "long"
                 }
                ],
                "type": "struct"
               }
              },
              {
               "metadata": {},
               "name": "filesRemoved",
               "nullable": true,
               "type": {
                "fields": [
                 {
                  "metadata": {},
                  "name": "min",
                  "nullable": true,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "max",
                  "nullable": true,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "avg",
                  "nullable": false,
                  "type": "double"
                 },
                 {
                  "metadata": {},
                  "name": "totalFiles",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "totalSize",
                  "nullable": false,
                  "type": "long"
                 }
                ],
                "type": "struct"
               }
              },
              {
               "metadata": {},
               "name": "partitionsOptimized",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "zOrderStats",
               "nullable": true,
               "type": {
                "fields": [
                 {
                  "metadata": {},
                  "name": "strategyName",
                  "nullable": true,
                  "type": "string"
                 },
                 {
                  "metadata": {},
                  "name": "inputCubeFiles",
                  "nullable": true,
                  "type": {
                   "fields": [
                    {
                     "metadata": {},
                     "name": "num",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "size",
                     "nullable": false,
                     "type": "long"
                    }
                   ],
                   "type": "struct"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "inputOtherFiles",
                  "nullable": true,
                  "type": {
                   "fields": [
                    {
                     "metadata": {},
                     "name": "num",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "size",
                     "nullable": false,
                     "type": "long"
                    }
                   ],
                   "type": "struct"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "inputNumCubes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "mergedFiles",
                  "nullable": true,
                  "type": {
                   "fields": [
                    {
                     "metadata": {},
                     "name": "num",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "size",
                     "nullable": false,
                     "type": "long"
                    }
                   ],
                   "type": "struct"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "numOutputCubes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "mergedNumCubes",
                  "nullable": true,
                  "type": "long"
                 }
                ],
                "type": "struct"
               }
              },
              {
               "metadata": {},
               "name": "clusteringStats",
               "nullable": true,
               "type": {
                "fields": [
                 {
                  "metadata": {},
                  "name": "inputZCubeFiles",
                  "nullable": true,
                  "type": {
                   "fields": [
                    {
                     "metadata": {},
                     "name": "numFiles",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "size",
                     "nullable": false,
                     "type": "long"
                    }
                   ],
                   "type": "struct"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "inputOtherFiles",
                  "nullable": true,
                  "type": {
                   "fields": [
                    {
                     "metadata": {},
                     "name": "numFiles",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "size",
                     "nullable": false,
                     "type": "long"
                    }
                   ],
                   "type": "struct"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "inputNumZCubes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "mergedFiles",
                  "nullable": true,
                  "type": {
                   "fields": [
                    {
                     "metadata": {},
                     "name": "numFiles",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "size",
                     "nullable": false,
                     "type": "long"
                    }
                   ],
                   "type": "struct"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "numOutputZCubes",
                  "nullable": false,
                  "type": "long"
                 }
                ],
                "type": "struct"
               }
              },
              {
               "metadata": {},
               "name": "numBins",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "numBatches",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "totalConsideredFiles",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "totalFilesSkipped",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "preserveInsertionOrder",
               "nullable": false,
               "type": "boolean"
              },
              {
               "metadata": {},
               "name": "numFilesSkippedToReduceWriteAmplification",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "numBytesSkippedToReduceWriteAmplification",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "startTimeMs",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "endTimeMs",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "totalClusterParallelism",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "totalScheduledTasks",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "autoCompactParallelismStats",
               "nullable": true,
               "type": {
                "fields": [
                 {
                  "metadata": {},
                  "name": "maxClusterActiveParallelism",
                  "nullable": true,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "minClusterActiveParallelism",
                  "nullable": true,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "maxSessionActiveParallelism",
                  "nullable": true,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "minSessionActiveParallelism",
                  "nullable": true,
                  "type": "long"
                 }
                ],
                "type": "struct"
               }
              },
              {
               "metadata": {},
               "name": "deletionVectorStats",
               "nullable": true,
               "type": {
                "fields": [
                 {
                  "metadata": {},
                  "name": "numDeletionVectorsRemoved",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numDeletionVectorRowsRemoved",
                  "nullable": false,
                  "type": "long"
                 }
                ],
                "type": "struct"
               }
              },
              {
               "metadata": {},
               "name": "recompressionCodec",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "numTableColumns",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "numTableColumnsWithStats",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "totalTaskExecutionTimeMs",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "skippedArchivedFiles",
               "nullable": false,
               "type": "long"
              },
              {
               "metadata": {},
               "name": "clusteringMetrics",
               "nullable": true,
               "type": {
                "fields": [
                 {
                  "metadata": {},
                  "name": "sizeOfTableInBytesBeforeLazyClustering",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "isNewMetadataCreated",
                  "nullable": false,
                  "type": "boolean"
                 },
                 {
                  "metadata": {},
                  "name": "isPOTriggered",
                  "nullable": false,
                  "type": "boolean"
                 },
                 {
                  "metadata": {},
                  "name": "isFull",
                  "nullable": false,
                  "type": "boolean"
                 },
                 {
                  "metadata": {},
                  "name": "approxClusteringQuality",
                  "nullable": true,
                  "type": "double"
                 },
                 {
                  "metadata": {},
                  "name": "approxClusteringQualityPerColumn",
                  "nullable": true,
                  "type": {
                   "containsNull": false,
                   "elementType": "double",
                   "type": "array"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "approxClusteringCoverage",
                  "nullable": true,
                  "type": "double"
                 },
                 {
                  "metadata": {},
                  "name": "numFilesSkippedWithoutStats",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numFilesClassifiedToIntermediateNodes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "sizeOfFilesClassifiedToIntermediateNodesInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "logicalSizeOfFilesClassifiedToIntermediateNodesInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numFilesClassifiedToLeafNodes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "sizeOfFilesClassifiedToLeafNodesInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "logicalSizeOfFilesClassifiedToLeafNodesInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numThreadsForClassifier",
                  "nullable": true,
                  "type": "integer"
                 },
                 {
                  "metadata": {},
                  "name": "clusterThresholdStrategy",
                  "nullable": true,
                  "type": "string"
                 },
                 {
                  "metadata": {},
                  "name": "minFileSize",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "maxFileSize",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "nodeMinNumFilesToCompact",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numIdealFiles",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numIdealFilesWithTrimmedStringMaxValue",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numAddedFilesWithSameMinMaxOnClusteringColumns",
                  "nullable": true,
                  "type": {
                   "containsNull": false,
                   "elementType": "long",
                   "type": "array"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "numClusteringTasksPlanned",
                  "nullable": false,
                  "type": "integer"
                 },
                 {
                  "metadata": {},
                  "name": "numCompactionTasksPlanned",
                  "nullable": false,
                  "type": "integer"
                 },
                 {
                  "metadata": {},
                  "name": "numOptimizeBatchesPlanned",
                  "nullable": false,
                  "type": "integer"
                 },
                 {
                  "metadata": {},
                  "name": "numLeafNodesExpanded",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numLeafNodesClustered",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numGetFilesForNodeCalls",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numSamplingJobs",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numLeafNodesCompacted",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numIntermediateNodesCompacted",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "totalSizeOfDataToCompactInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "totalLogicalSizeOfDataToCompactInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numIntermediateNodesClustered",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "numFilesSkippedAfterExpansion",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "totalSizeOfFilesSkippedAfterExpansionInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "totalLogicalSizeOfFilesSkippedAfterExpansionInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "totalSizeOfDataToRewriteInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "totalLogicalSizeOfDataToRewriteInBytes",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "timeMetrics",
                  "nullable": true,
                  "type": {
                   "fields": [
                    {
                     "metadata": {},
                     "name": "classifierTimeMs",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "optimizerTimeMs",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "metadataLoadTimeMs",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "totalGetFilesForNodeCallsTimeMs",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "totalSamplingTimeMs",
                     "nullable": false,
                     "type": "long"
                    },
                    {
                     "metadata": {},
                     "name": "metadataCreationTimeMs",
                     "nullable": false,
                     "type": "long"
                    }
                   ],
                   "type": "struct"
                  }
                 },
                 {
                  "metadata": {},
                  "name": "maxOptimizeBatchesInParallel",
                  "nullable": false,
                  "type": "long"
                 },
                 {
                  "metadata": {},
                  "name": "currentIteration",
                  "nullable": false,
                  "type": "integer"
                 },
                 {
                  "metadata": {},
                  "name": "maxIterations",
                  "nullable": false,
                  "type": "integer"
                 },
                 {
                  "metadata": {},
                  "name": "clusteringStrategy",
                  "nullable": true,
                  "type": "string"
                 }
                ],
                "type": "struct"
               }
              }
             ],
             "type": "struct"
            }
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 18
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "metrics",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"numFilesAdded\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numFilesRemoved\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"filesAdded\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"min\",\"nullable\":true,\"type\":\"long\"},{\"metadata\":{},\"name\":\"max\",\"nullable\":true,\"type\":\"long\"},{\"metadata\":{},\"name\":\"avg\",\"nullable\":false,\"type\":\"double\"},{\"metadata\":{},\"name\":\"totalFiles\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalSize\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"filesRemoved\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"min\",\"nullable\":true,\"type\":\"long\"},{\"metadata\":{},\"name\":\"max\",\"nullable\":true,\"type\":\"long\"},{\"metadata\":{},\"name\":\"avg\",\"nullable\":false,\"type\":\"double\"},{\"metadata\":{},\"name\":\"totalFiles\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalSize\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"partitionsOptimized\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"zOrderStats\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"strategyName\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"inputCubeFiles\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"num\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"size\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"inputOtherFiles\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"num\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"size\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"inputNumCubes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"mergedFiles\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"num\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"size\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"numOutputCubes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"mergedNumCubes\",\"nullable\":true,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"clusteringStats\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"inputZCubeFiles\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"numFiles\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"size\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"inputOtherFiles\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"numFiles\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"size\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"inputNumZCubes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"mergedFiles\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"numFiles\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"size\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"numOutputZCubes\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"numBins\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numBatches\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalConsideredFiles\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalFilesSkipped\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"preserveInsertionOrder\",\"nullable\":false,\"type\":\"boolean\"},{\"metadata\":{},\"name\":\"numFilesSkippedToReduceWriteAmplification\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numBytesSkippedToReduceWriteAmplification\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"startTimeMs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"endTimeMs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalClusterParallelism\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalScheduledTasks\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"autoCompactParallelismStats\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"maxClusterActiveParallelism\",\"nullable\":true,\"type\":\"long\"},{\"metadata\":{},\"name\":\"minClusterActiveParallelism\",\"nullable\":true,\"type\":\"long\"},{\"metadata\":{},\"name\":\"maxSessionActiveParallelism\",\"nullable\":true,\"type\":\"long\"},{\"metadata\":{},\"name\":\"minSessionActiveParallelism\",\"nullable\":true,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"deletionVectorStats\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"numDeletionVectorsRemoved\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numDeletionVectorRowsRemoved\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"recompressionCodec\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"numTableColumns\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numTableColumnsWithStats\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalTaskExecutionTimeMs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"skippedArchivedFiles\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"clusteringMetrics\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"sizeOfTableInBytesBeforeLazyClustering\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"isNewMetadataCreated\",\"nullable\":false,\"type\":\"boolean\"},{\"metadata\":{},\"name\":\"isPOTriggered\",\"nullable\":false,\"type\":\"boolean\"},{\"metadata\":{},\"name\":\"isFull\",\"nullable\":false,\"type\":\"boolean\"},{\"metadata\":{},\"name\":\"approxClusteringQuality\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"approxClusteringQualityPerColumn\",\"nullable\":true,\"type\":{\"containsNull\":false,\"elementType\":\"double\",\"type\":\"array\"}},{\"metadata\":{},\"name\":\"approxClusteringCoverage\",\"nullable\":true,\"type\":\"double\"},{\"metadata\":{},\"name\":\"numFilesSkippedWithoutStats\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numFilesClassifiedToIntermediateNodes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"sizeOfFilesClassifiedToIntermediateNodesInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"logicalSizeOfFilesClassifiedToIntermediateNodesInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numFilesClassifiedToLeafNodes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"sizeOfFilesClassifiedToLeafNodesInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"logicalSizeOfFilesClassifiedToLeafNodesInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numThreadsForClassifier\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"clusterThresholdStrategy\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"minFileSize\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"maxFileSize\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"nodeMinNumFilesToCompact\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numIdealFiles\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numIdealFilesWithTrimmedStringMaxValue\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numAddedFilesWithSameMinMaxOnClusteringColumns\",\"nullable\":true,\"type\":{\"containsNull\":false,\"elementType\":\"long\",\"type\":\"array\"}},{\"metadata\":{},\"name\":\"numClusteringTasksPlanned\",\"nullable\":false,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"numCompactionTasksPlanned\",\"nullable\":false,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"numOptimizeBatchesPlanned\",\"nullable\":false,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"numLeafNodesExpanded\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numLeafNodesClustered\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numGetFilesForNodeCalls\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numSamplingJobs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numLeafNodesCompacted\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numIntermediateNodesCompacted\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalSizeOfDataToCompactInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalLogicalSizeOfDataToCompactInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numIntermediateNodesClustered\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"numFilesSkippedAfterExpansion\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalSizeOfFilesSkippedAfterExpansionInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalLogicalSizeOfFilesSkippedAfterExpansionInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalSizeOfDataToRewriteInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalLogicalSizeOfDataToRewriteInBytes\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"timeMetrics\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"classifierTimeMs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"optimizerTimeMs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"metadataLoadTimeMs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalGetFilesForNodeCallsTimeMs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"totalSamplingTimeMs\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"metadataCreationTimeMs\",\"nullable\":false,\"type\":\"long\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"maxOptimizeBatchesInParallel\",\"nullable\":false,\"type\":\"long\"},{\"metadata\":{},\"name\":\"currentIteration\",\"nullable\":false,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"maxIterations\",\"nullable\":false,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"clusteringStrategy\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}}],\"type\":\"struct\"}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "optimize delta.`/Volumes/delta/deltaschema/optimization/optimize/` zorder by (id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78f05ad6-6684-4ee8-a2f6-171b07cd5ae9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>2</td><td>2025-07-12T13:51:30.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>OPTIMIZE</td><td>Map(predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0)</td><td>null</td><td>null</td><td>0712-134530-qhpwm4jy-v2n</td><td>1</td><td>SnapshotIsolation</td><td>false</td><td>Map(numRemovedFiles -> 2, numRemovedBytes -> 2106, p25FileSize -> 1089, numDeletionVectorsRemoved -> 1, minFileSize -> 1089, numAddedFiles -> 1, maxFileSize -> 1089, p75FileSize -> 1089, p50FileSize -> 1089, numAddedBytes -> 1089)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr><tr><td>1</td><td>2025-07-12T13:51:28.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>UPDATE</td><td>Map(predicate -> [\"(id#10828L = 1)\"])</td><td>null</td><td>null</td><td>0712-134530-qhpwm4jy-v2n</td><td>0</td><td>WriteSerializable</td><td>false</td><td>Map(numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 1, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 3493, numDeletionVectorsUpdated -> 0, scanTimeMs -> 2106, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1030, rewriteTimeMs -> 1352)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr><tr><td>0</td><td>2025-07-12T13:49:06.000Z</td><td>5763104327656046</td><td>dshkr2002@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>null</td><td>0712-134530-qhpwm4jy-v2n</td><td>null</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 4, numOutputBytes -> 1076)</td><td>null</td><td>Databricks-Runtime/16.4.x-aarch64-photon-scala2.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2,
         "2025-07-12T13:51:30.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "OPTIMIZE",
         {
          "auto": "true",
          "batchId": "0",
          "clusterBy": "[]",
          "predicate": "[]",
          "zOrderBy": "[]"
         },
         null,
         null,
         "0712-134530-qhpwm4jy-v2n",
         1,
         "SnapshotIsolation",
         false,
         {
          "maxFileSize": "1089",
          "minFileSize": "1089",
          "numAddedBytes": "1089",
          "numAddedFiles": "1",
          "numDeletionVectorsRemoved": "1",
          "numRemovedBytes": "2106",
          "numRemovedFiles": "2",
          "p25FileSize": "1089",
          "p50FileSize": "1089",
          "p75FileSize": "1089"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ],
        [
         1,
         "2025-07-12T13:51:28.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "UPDATE",
         {
          "predicate": "[\"(id#10828L = 1)\"]"
         },
         null,
         null,
         "0712-134530-qhpwm4jy-v2n",
         0,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "3493",
          "numAddedBytes": "1030",
          "numAddedChangeFiles": "0",
          "numAddedFiles": "1",
          "numCopiedRows": "0",
          "numDeletionVectorsAdded": "1",
          "numDeletionVectorsRemoved": "0",
          "numDeletionVectorsUpdated": "0",
          "numRemovedBytes": "0",
          "numRemovedFiles": "0",
          "numUpdatedRows": "1",
          "rewriteTimeMs": "1352",
          "scanTimeMs": "2106"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ],
        [
         0,
         "2025-07-12T13:49:06.000Z",
         "5763104327656046",
         "dshkr2002@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         null,
         "0712-134530-qhpwm4jy-v2n",
         null,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1076",
          "numOutputRows": "4"
         },
         null,
         "Databricks-Runtime/16.4.x-aarch64-photon-scala2.12"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "version",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "timestamp",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "userId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "userName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operation",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operationParameters",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "job",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "jobId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobName",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobRunId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "runId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobOwnerId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "triggerType",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "notebook",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "notebookId",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "clusterId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "readVersion",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "isolationLevel",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "isBlindAppend",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "operationMetrics",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "userMetadata",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "engineInfo",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 19
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"jobId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobName\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobRunId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"runId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobOwnerId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"triggerType\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"notebookId\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "describe history delta.`/Volumes/delta/deltaschema/optimization/optimize/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "712b45dd-da92-4665-b41b-cd6c0b44d81d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6267802596472622,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Delta Learning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}